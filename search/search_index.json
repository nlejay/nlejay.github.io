{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Accueil","text":"<p>En plein apprentissage de la Data Science, je pr\u00e9sente \u00e0 travers ce site quelques projets que j'ai r\u00e9alis\u00e9s \u00e0 partir de donn\u00e9es libres d'utilisation (Open Data). J'alimenterai le site au fur et \u00e0 mesure par de nouvelles r\u00e9alisations dans les domaines suivants :</p> <ul> <li>Nettoyage, manipulations, visualisation de donn\u00e9es en Python</li> <li>Nettoyage, manipulations, visualisation de donn\u00e9es sous tableur</li> <li>Requ\u00eates en SQL</li> <li>Tableaux de bord sous Power BI ou Tableau</li> </ul> <p>Dans chaque section, vous trouverez ma d\u00e9marche ainsi que le travail que j'ai effectu\u00e9 mais je ne pr\u00e9sente pas le code complet. En revanche, vous trouverez un lien vers les fichiers contenant les codes ainsi que les sources de donn\u00e9ees utilis\u00e9es.</p> <p>Vous pouvez me retrouver sur :</p> <ul> <li>Github : https://github.com/nlejay</li> <li>Linkedin : https://www.linkedin.com/in/nicolas-lejay-422817164/</li> </ul>"},{"location":"APropos/","title":"Mon parcours","text":"<ul> <li>J'ai commenc\u00e9 ma carri\u00e8re en tant que professeur de math\u00e9matiques en 2004. J'ai exerc\u00e9 ce m\u00e9tier en coll\u00e8ge et en lyc\u00e9e, en France m\u00e9tropolitaine mais \u00e9galement en Guyane dans un quartier d\u00e9favoris\u00e9 de la banlieue de Cayenne.</li> <li>En 2015, j'ai commenc\u00e9 \u00e0 me former en algorithmique et programmation en Python. Cela m'a permis d'enseigner la sp\u00e9cialit\u00e9 ISN (Informatique et Sciences du Num\u00e9rique) en terminale S de 2015 \u00e0 2019, puis la sp\u00e9cialit\u00e9 NSI (Num\u00e9rique et Sciences Informatiques) en premi\u00e8re et terminale depuis la r\u00e9forme du lyc\u00e9e mise en place en 2019.</li> <li>Aujourd'hui, je suis une formation de l'universit\u00e9 de Cergy pour devenir Data Analyst.</li> </ul>"},{"location":"competences/","title":"Comp\u00e9tences pour la Data Science","text":""},{"location":"competences/#mathematiques","title":"Math\u00e9matiques","text":""},{"location":"competences/#maitrise-des-fonctions-fondamentales-des-tableurs","title":"Ma\u00eetrise des fonctions fondamentales des tableurs","text":"<ul> <li>Fonctions de calculs</li> <li>Fonctions de recherche, de filtre</li> <li>Tableaux crois\u00e9s dynamiques</li> <li>Repr\u00e9sentations graphiques</li> </ul>"},{"location":"competences/#algorithmique-et-programmation-en-python","title":"Algorithmique et Programmation en Python","text":"<ul> <li>Concepts fondamentaux (structures conditionnelles, boucles, fonctions,...)</li> <li>Strucutures de donn\u00e9es (listes, dictionnaires, tuples, arbres, graphes, piles,...)</li> <li>Les bases de la Programmation Orient\u00e9e Objet</li> <li>Algorithmique (r\u00e9cursivit\u00e9, diviser pour r\u00e9gner, programmation dynamique, algorithmes gloutons,...)</li> </ul>"},{"location":"competences/#manipulation-de-donnees-en-python","title":"Manipulation de donn\u00e9es en Python","text":"<ul> <li>Nettoyage, manipulation de donn\u00e9es, jointures de dataframes,... (connaissance du module pandas)</li> <li>Visualisation de donn\u00e9es (modules matplotlib, seaborn, Folium)</li> </ul>"},{"location":"competences/#interrogation-de-bases-de-donnees-en-sql","title":"Interrogation de bases de donn\u00e9es en SQL","text":"<ul> <li>Requ\u00eates classiques (SELECT...FROM...WHERE), sous-requ\u00eates</li> <li>Jointure de tables</li> <li>Common Table Expressions (CTE)</li> <li>Window functions</li> </ul>"},{"location":"competences/#bases-de-machine-learning-en-python","title":"Bases de Machine Learning en Python","text":"<ul> <li>Module scikit-learn</li> <li>Algorithmes de r\u00e9gression, de classification et de clustering</li> <li>Entrainement et \u00e9valuation des mod\u00e8les (validation crois\u00e9e, recherche de minimisation des probl\u00e8mes d'underfitting et d'overfitting)</li> </ul>"},{"location":"competences/#notions-de-bases-du-logiciel-microsoft-power-bi","title":"Notions de bases du logiciel Microsoft Power BI","text":"<ul> <li>Importation et nettoyage de donn\u00e9es</li> <li>Tableaux de bords</li> <li>Data Analysis Expressions (DAX)</li> </ul>"},{"location":"experience/","title":"Experience professionnelle","text":""},{"location":"experience/#enseignant-en-mathematiques","title":"Enseignant en math\u00e9matiques","text":"<ul> <li>Lyc\u00e9e Eug\u00e8ne Freyssinet, Saint-Brieuc (22) | 2013-2022</li> <li>GRETA des C\u00f4tes d'Armor, Saint-Brieuc (22) | 2021-2022</li> <li>Coll\u00e8ge Lise Ophion, Matoury (Guyane fran\u00e7aise) | 2005-2013</li> <li>Lyc\u00e9e Aristide Briand, Saint-Nazaire (44) | 2004-2005</li> </ul>"},{"location":"experience/#enseignant-en-numerique-et-sciences-informatiques-nsi","title":"Enseignant en Num\u00e9rique et Sciences Informatiques (NSI)","text":"<ul> <li>Lyc\u00e9e Eug\u00e8ne Freyssinet, Saint-Brieuc (22) | 2019-2022</li> </ul>"},{"location":"experience/#enseignant-en-informatique-et-sciences-du-numerique-isn","title":"Enseignant en Informatique et Sciences du Num\u00e9rique (ISN)","text":"<ul> <li>Lyc\u00e9e Eug\u00e8ne Freyssinet, Saint-Brieuc (22) | 2015-2019</li> </ul>"},{"location":"formation/","title":"Formation","text":""},{"location":"formation/#universite-de-cergy","title":"Universit\u00e9 de Cergy","text":"<ul> <li>DU Data Analyst | Mars-d\u00e9cembre 2023 (en cours)</li> </ul>"},{"location":"formation/#centre-national-denseignement-a-distance-cned","title":"Centre National d'Enseignement \u00e0 Distance (CNED)","text":"<ul> <li>Pr\u00e9paration au CAPES de math\u00e9matiques  | 2002-2003</li> <li>Re\u00e7u au concours du CAPES en 2003</li> </ul>"},{"location":"formation/#universite-de-rennes-1","title":"Universit\u00e9 de Rennes 1","text":"<ul> <li>DIU Enseigner l'informatique au lyc\u00e9e (Formation continue pour les enseignants) | 2019-2020</li> </ul>"},{"location":"formation/#plateforme-fun-mooc","title":"Plateforme FUN-MOOC","text":"<ul> <li>MOOC Python 3 : des fondamentaux aux concepts avanc\u00e9s | 2018</li> <li>MOOC Machine learning in Python with scikit-learn | Nov 2022-Janv 2023</li> </ul>"},{"location":"formation/#plateforme-datacamp","title":"Plateforme Datacamp","text":"<ul> <li>Cours de traitement de donn\u00e9es en Python <ul> <li>Importing and cleaning data with Python</li> <li>Data Manipulation with Python</li> <li>Data Visualization with Python</li> </ul> </li> <li>Cours de traitement de donn\u00e9es avec tableur<ul> <li>Spreadsheet fundamentals</li> </ul> </li> <li>Cours de requ\u00eates de bases de donn\u00e9es<ul> <li>SQL fundamentals</li> </ul> </li> <li>Cours d'utilisation du logiciel Microsoft Power BI<ul> <li>Power BI fundamentals</li> </ul> </li> </ul>"},{"location":"formation/#institut-catholique-des-arts-et-metiers-de-lille-icam","title":"Institut Catholique des Arts et M\u00e9tiers de Lille (ICAM)","text":"<ul> <li>Dipl\u00f4me d'ing\u00e9nieur | 1996-2001</li> </ul>"},{"location":"projets/PBI_accidents/","title":"Exploration de donn\u00e9es sur les accidents corporels de la circulation routi\u00e8re en 2021","text":""},{"location":"projets/PBI_accidents/#competences-mises-en-uvre","title":"Comp\u00e9tences mises en \u0153uvre","text":"<ul> <li>Utilisation de Power Query pour importer, transformer des donn\u00e9es, puis les charger dans Power BI.</li> <li>Cr\u00e9ation de visualisations graphiques des donn\u00e9es, utilisation de filtres.</li> <li>Cr\u00e9ation de nouvelles colonnes, nouvelles mesures et nouvelles tables de donn\u00e9es.</li> <li>Travail sur les dates.</li> <li>Utilisation de boutons de navigation entre les pages.</li> </ul>"},{"location":"projets/PBI_accidents/#problematique","title":"Probl\u00e9matique","text":"<p>Le but de ce projet \u00e9tait de mettre en \u0153uvre mes premi\u00e8res connaissances des fonctionnalit\u00e9s de Microsoft Power BI. J'ai pour cela utilis\u00e9 un jeu de donn\u00e9es regroupant des caract\u00e9ristiques des accidents corporels de la circulation routi\u00e8re en France en 2021. Ce jeu de donn\u00e9es \u00e9tant tr\u00e8s riche, le but n'\u00e9tait pas de l'exploiter compl\u00e8tement mais simplement de mettre en pratique mes comp\u00e9tences et d'en tirer quelques informations \u00e0 travers un tableau de bord.</p> <p>Donn\u00e9es utilis\u00e9es</p> <p>J'ai utilis\u00e9 un jeu de donn\u00e9es open data mis \u00e0 disposition par le minist\u00e8re de l'int\u00e9rieur. Ce jeu de donn\u00e9es se compose de quatre fichiers CSV :</p> <ul> <li>le fichier caracteristiques_2021.csv comportant les caract\u00e9ristiques principales de chaque accident : jour, heure, adresse, conditions climatiques et de luminosit\u00e9,...</li> <li>le fichier lieux_2021.csv qui regroupe des informations plus pr\u00e9cises sur le lieu o\u00f9 s'est produit chaque accident : type de voirie, \u00e9tat de la chauss\u00e9e, profil de la route,...</li> <li>le fichier usagers_2021.csv qui regroupe des informations sur les victimes : genre, gravit\u00e9 de la blessure, cat\u00e9gorie de la personne (conducteur, passager, pi\u00e9ton), type de trajet effectu\u00e9,...</li> <li>le fichier vehicules_2021.csv qui regroupe des informations sur les v\u00e9hicules impliqu\u00e9s dans les accidents : type de v\u00e9hicule, point du choc,...</li> </ul> <p>Tous ces fichiers ainsi que le document de description des diff\u00e9rentes variables sont accessibles ici</p>"},{"location":"projets/PBI_accidents/#importation-transformation-et-nettoyage-des-donnees","title":"Importation, transformation et nettoyage des donn\u00e9es","text":"<p>La premi\u00e8re op\u00e9ration est d'importer les donn\u00e9es. Cela se fait fichier par fichier. Avant de charger les donn\u00e9es dans Power BI, il faut v\u00e9rifier leur type, les donn\u00e9es manquantes, les erreurs,...</p> <p>Les types de donn\u00e9es</p> <p>Lors de l'importation, Power query d\u00e9tecte automatiquement le type de donn\u00e9es. Mais ce type peut \u00eatre modifi\u00e9 en fonction de nos besoins. Par exemple pour chaque fichier le num\u00e9ro d'accident Num_Acc est consid\u00e9r\u00e9 comme nombre entier par Power Query (voir image ci-dessous). Pr\u00e9f\u00e9rant l'avoir au format texte, je l'ai modifi\u00e9 en choisissant texte dans la liste d\u00e9roulante du type de donn\u00e9es.</p> <p></p> <p>Le travail de v\u00e9rification du type de donn\u00e9es est \u00e0 faire pour chaque variable.</p> <p>Les erreurs</p> <p>A l'importation, la variable actp de la table usagers_2021 comportait des erreurs (voir ci-dessous l'indication d'erreurs). Cette variable correspond \u00e0 l'action du pi\u00e9ton au moment de l'accident si la victime est un pi\u00e9ton. Chaque action est cod\u00e9e par un nombre entier : par exemple, 3 signifie que le pi\u00e9ton traversait la chauss\u00e9e. </p> <p></p> <p>Alors que toutes les donn\u00e9es de la variable devraient \u00eatre num\u00e9riques, apr\u00e8s recherche je me suis aper\u00e7u qu'il existait parfois des donn\u00e9es saisies sous forme de caract\u00e8res. C'est pour ces valeurs que Power Query indique une erreur. Pour corriger le probl\u00e8me, j'ai d\u00e9cid\u00e9 de cr\u00e9er une nouvelle colonne nomm\u00e9e actp_corr en utilisant la fonctionnalit\u00e9 Colonne personnalis\u00e9e de Power Query. L'id\u00e9e est de remplacer chaque erreur par -1, code correspondant \u00e0 l'absence de renseignement sur l'action du pi\u00e9ton. Il n'est en effet pas possible de retrouver la v\u00e9ritable action du pi\u00e9ton au moment de l'accident. La formule ci-dessous permet pour chaque ligne de r\u00e9cup\u00e9rer la valeur de la variable si elle est correcte et de remplacer les erreurs par -1.</p> <p></p> <p>Valeurs manquantes</p> <p>Certaines variables contiennent des valeurs manquantes (not\u00e9es null). Ces variables \u00e9taient toutes des variables cod\u00e9es par des nombres et dont -1 signifie \"Non renseign\u00e9\". J'ai donc remplac\u00e9 les valeurs manquantes par -1.</p> <p> </p> <p></p> <p>Recodage de variables</p> <p>Le fait que les variables soient cod\u00e9es par des valeurs num\u00e9riques n'est pas pratique pour la constitution de visualisations graphiques. Cr\u00e9er de nouvelles colonnes avec la signification de ces codes est important. Pour cela, on peut utiliser la fonctionnalit\u00e9 Colonne conditionnelle comme sur l'image ci-dessous.</p> <p></p> <p>Cr\u00e9ation d'une variable horaire </p> <p>Dans le jeu de donn\u00e9es, l'heure d'un accident est indiqu\u00e9 \u00e0 la minute pr\u00e8s. Pour r\u00e9aliser une \u00e9tude temporelle, je voulais regrouper les accidents par classes : une classe par heure. Par exemple, tous les accidents ayant eu lieu entre 14h et 14h59 devaient appartenir \u00e0 la m\u00eame classe nomm\u00e9e 14.</p> <p>Pour cela, il est facile de cr\u00e9er une nouvelle variable horaire gr\u00e2ce \u00e0 la fonction Time.hour qui r\u00e9cup\u00e8re l'heure d'une variable de type heure.</p> <p></p> <p>Chargement des donn\u00e9es</p> <p>Une fois toutes ces op\u00e9rations faites, il ne reste plus qu'\u00e0 charger les donn\u00e9es dans Power BI.</p>"},{"location":"projets/PBI_accidents/#relations-entre-les-tables","title":"Relations entre les tables","text":"<p>Avant de se lancer dans un tableau de bord, il faut relier les tables entre elles. Ici, les diff\u00e9rentes tables sont \u00e0 relier sur le num\u00e9ro d'accident Num_Acc. Cela se fait dans l'onglet mod\u00e8le de Power BI. On remarquera sur l'image ci-dessous une table Dates. Cette table ne fait pas partie du jeu de donn\u00e9es initial. Je l'ai cr\u00e9\u00e9e pour faire une \u00e9tude temporelle des accidents (voir paragraphe correspondant).</p> <p></p>"},{"location":"projets/PBI_accidents/#creation-du-tableau-de-bord","title":"Cr\u00e9ation du tableau de bord","text":"<p>Comme dit plus haut, le but de ce travail n'\u00e9tait pas de faire un rapport ou un tableau de bord exhaustif de toutes les informations que l'on peut tirer de ce jeu de donn\u00e9es. Je ne pr\u00e9senterai donc que quelques pages avec des visualisations graphiques permettant de tirer quelques enseignements du jeu de donn\u00e9es.</p>"},{"location":"projets/PBI_accidents/#aspect-des-pages","title":"Aspect des pages","text":"<p>Avant de me lancer dans la cr\u00e9ation des diff\u00e9rentes pages, j'ai r\u00e9fl\u00e9chi \u00e0 la forme qu'elles prendraient. Voici ce que j'ai d\u00e9cid\u00e9 :</p> <ul> <li>Pr\u00e9sence d'une page d'accueil</li> <li>Pr\u00e9sence d'un titre pour chaque page</li> <li>Pr\u00e9sence de boutons permettant de naviguer de pages en pages</li> </ul> <p>Une fois ces \u00e9l\u00e9ments mis en place, on peut cr\u00e9er pour chaque page les visualisations souhait\u00e9es. Voici les exemples de la page d'accueil et d'une page du tableau de bord :</p> <p></p> <p></p> <p>Je ne m'\u00e9tendrai pas sur la page Aper\u00e7u g\u00e9n\u00e9ral qui n'est constitu\u00e9e que de graphiques basiques. Passons directement \u00e0 la page sur les accidents mortels.</p>"},{"location":"projets/PBI_accidents/#page-sur-les-accidents-mortels-creation-de-nouvelles-mesures","title":"Page sur les accidents mortels - Cr\u00e9ation de nouvelles mesures","text":"<p>Pour constituer la page ci-dessus, j'ai d\u00fb cr\u00e9er de nouvelles mesures et donc utiliser les DAX. La premi\u00e8re est le nombre d'accidents mortels. Pour cela, il suffit de compter dans la table caract\u00e9ristiques le nombre de num\u00e9ros d'accident pour lesquels il y a eu un mort (gravit\u00e9 \u00e9gale \u00e0 2 dans la table usagers). Pour filtrer les donn\u00e9es suivant la gravit\u00e9 de l'accident, on a besoin d'utiliser la fonction <code>CALCULATE</code>.</p> <p></p> <p>La deuxi\u00e8me mesure cr\u00e9\u00e9e est le nombre de morts. Cela se fait de la m\u00eame mani\u00e8re en comptant cette fois le nombre d'usagers dont la gravit\u00e9 de l'accident est \u00e9tablie \u00e0 2.</p> <p></p> <p>Quant \u00e0 la variable comptabilisant le nombre d'accidents, il s'agit simplement d'un d\u00e9compte du nombre de num\u00e9ros d'accident.</p> <p></p> <p>Enfin, j'ai eu besoin de calculer le pourcentage d'accidents mortels parmi tous les accidents. Cela se fait tr\u00e8s facilement \u00e0 l'aide des mesures cr\u00e9\u00e9es pr\u00e9c\u00e9demment.</p> <p></p>"},{"location":"projets/PBI_accidents/#etude-temporelle-travail-sur-les-dates","title":"\u00c9tude temporelle - Travail sur les dates","text":"<p>Cr\u00e9ation d'une variable date</p> <p>Le jeu de donn\u00e9es comporte trois colonnes pour les dates : une pour l'ann\u00e9e, une pour le mois et une pour le jour. Cela est tr\u00e8s pratique si l'on veut par exemple analyser le nombre d'accidents par mois. Mais on peut \u00eatre amen\u00e9 \u00e0 utiliser la date compl\u00e8te d'un accident. Pour cela, il est plus pratique d'avoir \u00e9galement une variable contenant cette date. Il est facile d'obtenir cette colonne gr\u00e2ce \u00e0 la fonction <code>Date</code> \u00e0 laquelle il suffit de passer l'ann\u00e9e, le mois et le jour comme param\u00e8tres.</p> <p></p> <p>Cr\u00e9ation d'une table Dates</p> <p>En cr\u00e9ant la variable date, on obtient pour chaque accident la date \u00e0 laquelle il a eu lieu. M\u00eame s'il y a peu de chances que cela se produise, il peut exister un jour sans accident et donc manquer une date parmi toutes les dates de l'ann\u00e9e. Or pour certains calculs ou graphiques, il est important d'avoir une variable contenant toutes les dates comprises entre la premi\u00e8re et la derni\u00e8re date du jeu de donn\u00e9es. J'ai donc cr\u00e9\u00e9 une nouvelle table Dates contenant une variable Date poss\u00e9dant toutes ces dates. Pour cela, on peut utiliser la fonction <code>CALENDAR</code> et lui passer en param\u00e8tres la premi\u00e8re et la derni\u00e8re date du jeu de donn\u00e9es.</p> <p></p> <p>Dans cette table, j'ai \u00e9galement d\u00e9cid\u00e9 de cr\u00e9er une colonne contenant le num\u00e9ro du jour de la semaine et une autre contenant le nom du jour de la semaine. Cela peut permettre d'\u00e9tudier les accidents en fonction du jour de la semaine.</p> <p></p> <p></p> <p>Enfin, voulant comparer les accidents ayant lieu le week-end et ceux de la semaine, j'ai cr\u00e9\u00e9 une variable weekend en utilisant une simple structure conditionnelle.</p> <p></p> <p>Voici la table Dates cr\u00e9\u00e9e :</p> <p></p> <p>A partir de toutes les mesures, tables et colonnes cr\u00e9\u00e9es, j'ai pu organiser la page pr\u00e9sent\u00e9e au d\u00e9but de cette section sur les accidents mortels en fonction de diff\u00e9rentes variables temporelles (moi, heure, jour de la semaine).</p> <p>On peut noter que j'ai inclu des slicers/segments qui sont des filtres permettant d'inspecter les donn\u00e9es en se focalisant sur des types particuliers d'accidents. Par exemple, l'image ci-dessous montre la page apr\u00e8s avoir s\u00e9lectionn\u00e9 uniquement les accidents survenus sur un trajet domicile-travail. On voit bien appara\u00eetre les deux pics d'horaires d'entr\u00e9e et de sortie du travail sur la courbe pr\u00e9sentant le nombre d'accidents. En revanche, on constate que ce n'est pas sur ces horaires que la proportion d'accidents mortels est la plus \u00e9lev\u00e9e.</p> <p></p>"},{"location":"projets/ips/","title":"Indice de Position Sociale (IPS) des lyc\u00e9es fran\u00e7ais","text":""},{"location":"projets/ips/#competences-mises-en-uvre","title":"Comp\u00e9tences mises en \u0153uvre","text":"<ul> <li>Nettoyage, validation de donn\u00e9es</li> <li>Visualisation de donn\u00e9es (histogrammes, nuages de points, diagrammes en barres)</li> <li>Fonctions d'agr\u00e9gation classiques</li> <li>Tableaux crois\u00e9s dynamiques</li> <li>Fonctions avanc\u00e9es (<code>XLOOKUP</code>, <code>FILTER</code>,...)</li> <li>Tableau de bord int\u00e9ractif</li> </ul>"},{"location":"projets/ips/#problematique","title":"Probl\u00e9matique","text":"<p>D\u00e9but 2023, le minist\u00e8re de l'\u00e9ducation nationale a d\u00e9voil\u00e9 l'Indice de Position Sociale des lyc\u00e9es fran\u00e7ais. Cet indice permet d'attribuer une valeur quantitative \u00e0 l'origine sociale des \u00e9l\u00e8ves. Plus l'indice est grand, plus l'\u00e9l\u00e8ve est issu d'une cat\u00e9gorie sociale consid\u00e9r\u00e9e comme favorable \u00e0 sa r\u00e9ussite scolaire. Cet indicateur est calcul\u00e9 \u00e0 partir de plusieurs crit\u00e8res : dipl\u00f4mes des parents, conditions mat\u00e9rielles dans le foyer (nombre de pi\u00e8ces du logement, chambre seul, ordinateur,...), revenus des parents,... L'IPS attribu\u00e9 \u00e0 un lyc\u00e9e est une moyenne des IPS des \u00e9l\u00e8ves de l'\u00e9tablissement.</p> <p>Le but de ce petit projet \u00e9tait d'utiliser les fonctionnalit\u00e9s d'un tableur pour explorer le jeu de donn\u00e9es et en tirer des informations \u00e0 partir de calculs et de repr\u00e9sentations graphiques. Je tiens \u00e0 pr\u00e9ciser que je ne fais ici que des constats et qu'aucun jugement sur les r\u00e9sultats ne sera prononc\u00e9.</p> <p>Le fichier contenant le travail effectu\u00e9 est disponible ici au format xlsx.</p>"},{"location":"projets/ips/#presentation-du-jeu-de-donnees","title":"Pr\u00e9sentation du jeu de donn\u00e9es","text":"<p>Les donn\u00e9es repr\u00e9sentent la situation des lyc\u00e9es lors de l'ann\u00e9e scolaire 2021-2022. Le jeu de donn\u00e9es est constitu\u00e9 de 13 colonnes dont voici une description pour les plus importantes :</p> <ul> <li>academie : academie dans laquelle se situe le lyc\u00e9e</li> <li>uai : code UAI de l'\u00e9tablissement (permet d'identifier l'\u00e9tablissement de mani\u00e8re unique)</li> <li>nom_de_l_\u00e9tablissement</li> <li>nom_de_la_commune</li> <li>secteur : indique si l'\u00e9tablissement est public ou priv\u00e9 sous contrat</li> <li>type_de_lycee : indique si l'\u00e9tablissement est un LEGT (Lyc\u00e9e d'Enseignement G\u00e9n\u00e9ral et Technologique), un LP (Lyc\u00e9e Professionnel) ou un LPO (Lyc\u00e9e Polyvalent qui regroupe une section GT et une section professionnelle)</li> <li>ips_voie_gt : IPS de l'\u00e9tablissement si c'est un LEGT, IPS de la seule section GT si c'est un LPO, vide si c'est un LP</li> <li>ips_voie_pro : IPS de l'\u00e9tablissement si c'est un LP, IPS de la seule section Pro si c'est un LPO, vide si c'est un LEGT</li> <li>ips_ensemble_gt_pro : ips de l'ensemble de l'\u00e9tablissement</li> </ul> <p></p>"},{"location":"projets/ips/#premiers-resumes-statistiques","title":"Premiers r\u00e9sum\u00e9s statistiques","text":"<p>Des premiers param\u00e8tres statistiques sont faciles \u00e0 obtenir \u00e0 l'aide des fonctions <code>AVERAGE</code>, <code>STDEV</code>, <code>MEDIAN</code>, ou encore <code>MIN</code> et <code>MAX</code>. On obtient les r\u00e9sultats suivants :</p> <ul> <li>l'IPS moyen est de 103,91 avec un \u00e9cart-type de 18,9 ;</li> <li>l'IPS m\u00e9dian est de 103,8 ;</li> <li>l'IPS le plus petit est de 49,5 et le plus grand est de 159.</li> </ul> <p>On remarque que la moyenne et la m\u00e9diane sont proches, ce qui am\u00e8ne \u00e0 penser \u00e0 une certaine sym\u00e9trie de la r\u00e9partition des \u00e9tablissements selon leur IPS, ce qui est confirm\u00e9 en tra\u00e7ant un histogramme \u00e0 l'aide du tableur.</p> <p></p>"},{"location":"projets/ips/#comparaison-des-etablissements-suivant-leur-type","title":"Comparaison des \u00e9tablissements suivant leur type","text":"<p>Les param\u00e8tres pr\u00e9c\u00e9dents n'ont qu'un int\u00e9r\u00eat limit\u00e9 pour comprendre le jeu de donn\u00e9es. On peut pousser l'analyse plus loin en comparant les \u00e9tablissements en fonction de leur type. On peut calculer les m\u00eames param\u00e8tres mais cette fois pour chaque type d'\u00e9tablissement (LGT, LP, LPO). J'ai utilis\u00e9 pour cela une <code>pivot table</code> (tableau crois\u00e9 dynamique).</p> <p></p> <p>On s'aper\u00e7oit alors que les LGT accueillent en moyenne des \u00e9l\u00e8ves plus favoris\u00e9s socialement que les LP. Il existe n\u00e9anmoins des LGT \u00e0 IPS faible et des LP \u00e0 IPS \u00e9lev\u00e9. Cela n'est pas pr\u00e9sent\u00e9 dans le tableau ci-dessus mais la position interm\u00e9diaire des LPO est due au fait qu'ils comportent \u00e0 la fois une section GT et une section Pro. Leur section GT accueille en moyenne des \u00e9l\u00e8ves \u00e0 IPS plus \u00e9lev\u00e9s que ceux de leur section Pro (108,11 contre 88,29).</p> <p>Pour confirmer cet \u00e9cart entre les LGT et les LP, regardons la r\u00e9partition des lyc\u00e9es en fonction de leur type (dans le diagramme ci-dessous, les LPO sont inclus mais leur section GT a \u00e9t\u00e9 incluse aux donn\u00e9es des LGT et leur section Pro aux donn\u00e9es des LP). Le diagramme montre clairement la diff\u00e9rence des populations des LGT et des LP.</p> <p></p> Remarque technique <p>Pour r\u00e9aliser cet histogramme, il faut utiliser deux s\u00e9ries de donn\u00e9es : une pour chaque section. Cela est facilit\u00e9 ici par le fait qu'il existe d\u00e9j\u00e0 une colonne sp\u00e9cifique regroupant l'IPS des sections GT et une autre pour les sections Pro. Si cela n'avait pas \u00e9t\u00e9 le cas, il aurait \u00e9t\u00e9 prossible de faire un tri des donn\u00e9es selon le type de l'\u00e9tablissement.</p> <p>J'ai \u00e9galement calcul\u00e9 la proportion des \u00e9tablissements de chaque type dont l'IPS est sup\u00e9rieur ou \u00e9gal \u00e0 la moyenne de l'ensemble des \u00e9tablissements :</p> <p></p> <p>On s'aper\u00e7oit que 84,25 % des LGT ont un IPS sup\u00e9rieur ou \u00e9gal \u00e0 l'IPS moyen, ce qui n'est le cas que pour 6,63 % des LP.</p> Remarque technique <p>Pour r\u00e9aliser ce calcul, il  faut compter le nombre de lyc\u00e9es qui sont des LGT et qui ont un IPS sup\u00e9rieur \u00e0 la moyenne afin de diviser le r\u00e9sultat par le nombre total de LGT. Cela se fait facilement \u00e0 l'aide de la fonction <code>COUNTIFS</code> (<code>NB.SI.ENS</code> en fran\u00e7ais).</p> <p>On peut faire le m\u00eame type de comparaison sur les 100 \u00e9tablissements aux IPS les plus \u00e9lev\u00e9s. On trouve alors que ce sont tous des LGT !</p> <p>Concernant les 100 \u00e9tablissements aux IPS les moins \u00e9lev\u00e9s, on trouve 75 LP, 21 LPO et seulement 4 LGT. </p>"},{"location":"projets/ips/#comparaison-des-etablissements-suivant-leur-secteur","title":"Comparaison des \u00e9tablissements suivant leur secteur","text":"<p>Il est aussi int\u00e9ressant de comparer les secteurs publics et priv\u00e9s. L\u00e0-aussi, \u00e0 l'aide d'une <code>pivot table</code>, on obtient les r\u00e9sultats suivants :</p> <p></p> <p>On s'aper\u00e7oit qu'en moyenne les lyc\u00e9es priv\u00e9s poss\u00e8dent des \u00e9l\u00e8ves plus favoris\u00e9s socialement. Mais on remarquera n\u00e9anmoins que l'IPS minimal est celui d'un lyc\u00e9e priv\u00e9 et que l'IPS maximal est celui d'un lyc\u00e9e public. Cependant, ces derniers font figures d'exception. En effet, lorsque l'on regarde les 100 \u00e9tablissements les plus favoris\u00e9s, 80 sont priv\u00e9s et seulement 20 sont publics. Du c\u00f4t\u00e9 des 100 \u00e9tablissements aux \u00e9l\u00e8ves les moins favoris\u00e9s, 84 sont publics et seulement 16 sont priv\u00e9s.</p> <p>De m\u00eame, 65,8 % des lyc\u00e9es priv\u00e9s ont un IPS sup\u00e9rieur \u00e0 la moyenne alors que ce n'est le cas que de 41,5 % des \u00e9tablissements publics. </p> <p>Voici la r\u00e9partition des lyc\u00e9es suivant leur IPS en fonction de leur secteur :</p> <p></p> <p>Pour terminer cette comparaison, on peut voir sur le diagramme ci-dessous que quel que soit le type d'\u00e9tablissement, le secteur priv\u00e9 accueille en moyenne des \u00e9l\u00e8ves plus favoris\u00e9s que le secteur public.</p> <p></p> Remarque technique <p>Pour r\u00e9aliser les calculs et les diagrammes de cette partie, j'ai utilis\u00e9 les m\u00eames m\u00e9thodes que pour la partie pr\u00e9c\u00e9dente. La seule chose qui change est le fait de r\u00e9partir les donn\u00e9es suivant le secteur plut\u00f4t que le type.</p>"},{"location":"projets/ips/#correlation-entre-ips-et-reussite-au-bac","title":"Corr\u00e9lation entre IPS et r\u00e9ussite au bac ?","text":"<p>On peut se poser la question : y-a-t-il une meilleure r\u00e9ussite chez les \u00e9l\u00e8ves dont l'IPS est le plus grand ? Regardons s'il existe une corr\u00e9lation entre le taux de r\u00e9ussite au bac des lyc\u00e9es et leur IPS.</p> <p>Pour cela, j'ai utilis\u00e9 un deuxi\u00e8me jeu de donn\u00e9es disponible sur le site data.education.gouv.fr. On trouve dans ce jeu de donn\u00e9es le nom et le code UAI des lyc\u00e9es de type GT ainsi qu'un certain nombre de variables dont celle qui nous int\u00e9resse : le taux de r\u00e9ussite au baccalaur\u00e9at en 2021. On peut alors tracer un nuage de points repr\u00e9sentant le taux de r\u00e9ussite au bac en fonction de l'IPS des lyc\u00e9es (la droite rouge est la droite de r\u00e9gression lin\u00e9aire).</p> Remarque technique <p>Pour juxtaposer l'IPS et le taux de r\u00e9ussite au bac d'un m\u00eame \u00e9tablissement, il faut mettre en relation les deux jeux de donn\u00e9es (faire une sorte de jointure de tables). On peut par exemple partir du jeu de donn\u00e9es sur le taux de r\u00e9ussite au bac et aller chercher pour chaque \u00e9tablissement l'IPS correspondant. J'ai utilis\u00e9 pour cela la fonction <code>XLOOKUP</code> qui m'a permis de faire une recherche de l'IPS d'un \u00e9tablissement \u00e0 partir de son code UAI. </p> <p></p> <p>Le nuage de points ci-dessus permet remarquer que dans l'ensemble le taux de r\u00e9ussite est meilleur lorsque l'IPS devient grand, m\u00eame s'il existe de tr\u00e8s bons taux de r\u00e9ussite dans des lyc\u00e9es avec un IPS moyen voire faible. Cependant, il n'est pas possible de mod\u00e9liser cela par un mod\u00e8le de r\u00e9gression lin\u00e9aire. En effet, les r\u00e9sidus de ce mod\u00e8le ne suivent pas une distribution normale (voir Q-Q plot ci-dessous) et on constate \u00e9galement une h\u00e9t\u00e9rosc\u00e9dasticit\u00e9 : la variance des r\u00e9sidus est plus importante pour les faibles valeurs pr\u00e9dites (voir graphique des r\u00e9sidus en fonction des valeurs pr\u00e9dites).</p> Remarque technique <p>Pour r\u00e9aliser ces graphiques, il a fallu calculer les r\u00e9sidus (diff\u00e9rence entre valeur r\u00e9elle et valeur pr\u00e9dite), les trier, les normaliser puis les mettre en relation avec les quantiles d'une distribution normale.</p> <p></p> <p>J'ai alors r\u00e9alis\u00e9 un test de corr\u00e9lation de Spearman. Celui-ci r\u00e9v\u00e8le une corr\u00e9lation monotone forte entre le taux de r\u00e9ussite au bac et l'IPS (p-value &lt; 0,0001***). Cependant, cette corr\u00e9lation reste moyenne puisque le coefficient de Spearman est \u00e9gal \u00e0 0,54.</p> <p>Des calculs permettent tout de m\u00eame de remarquer que le taux moyen de r\u00e9ussite dans les lyc\u00e9es \u00e0 IPS inf\u00e9rieur \u00e0 100 est de 94 % alors qu'il est de 98 % dans les lyc\u00e9es \u00e0 IPS sup\u00e9rieur \u00e0 100. De m\u00eame, 86 % des lyc\u00e9es \u00e0 IPS inf\u00e9rieur \u00e0 100 ont un taux de r\u00e9ussite sup\u00e9rieur \u00e0 90 %. Or ce taux s'\u00e9l\u00e8ve \u00e0 99 % pour les lyc\u00e9es \u00e0 IPS sup\u00e9rieur \u00e0 100.</p> <p>On peut tout de m\u00eame \u00e9mettre des r\u00e9serves sur cette analyse :</p> <ul> <li>En 2021, la crise du covid-19 \u00e9tait encore bien pr\u00e9sente. Beaucoup de lyc\u00e9es ont utilis\u00e9 un fonctionnement hybride pr\u00e9sentiel-distanciel pendant une bonne partie de l'ann\u00e9e scolaire. Pour tenir compte des difficult\u00e9s d'apprentissage des \u00e9l\u00e8ves, les \u00e9preuves du bac ont \u00e9t\u00e9 am\u00e9nag\u00e9es. Les taux de r\u00e9ussite sont donc \u00e0 prendre avec du recul.</li> <li>Depuis la r\u00e9forme du lyc\u00e9e initi\u00e9e en 2019, le contr\u00f4le continu a pris une grande place dans le r\u00e9sultats du bac (40 % de la note finale). On peut se demander si tous les \u00e9tablissements jouent le jeu ou si certains ont tendance \u00e0 gonfler les notes pour obtenir de meilleurs r\u00e9sultats au bac. Est-on not\u00e9 de la m\u00eame mani\u00e8re dans tous les lyc\u00e9es de France ?</li> </ul>"},{"location":"projets/ips/#tableau-de-bord-interactif","title":"Tableau de bord interactif","text":"<p>Pour permettre d'analyser les donn\u00e9es pour chaque acad\u00e9mie, j'ai choisi de r\u00e9aliser un tableau de bord interactif. Celui-ci est compos\u00e9 d'un menu d\u00e9roulant permettant de choisir une acad\u00e9mie. La fonction <code>FILTER</code> permet alors de ne faire appara\u00eetre que les donn\u00e9es des lyc\u00e9es de cette acad\u00e9mie. Deux tableaux (IPS par secteur et IPS par type de lyc\u00e9e) ainsi que les deux diagrammes correspondants s'actualisent alors automatiquement.</p> <p></p>"},{"location":"projets/medecins/","title":"Cartographie de la densit\u00e9 de m\u00e9decins g\u00e9n\u00e9ralistes par bassin de vie","text":""},{"location":"projets/medecins/#competences-mises-en-uvre","title":"Comp\u00e9tences mises en \u0153uvre","text":"<ul> <li>Nettoyage de donn\u00e9es</li> <li>Manipulation de donn\u00e9es</li> <li>Jointures de tables (classiques et spatiales)</li> <li>Visualisation de donn\u00e9es (carte choropl\u00e8the)</li> </ul>"},{"location":"projets/medecins/#problematique","title":"Probl\u00e9matique","text":"<p>L'id\u00e9e de ce projet \u00e9tait d'\u00e9tablir en Python une carte choropl\u00e8the indiquant la densit\u00e9 de m\u00e9decins g\u00e9n\u00e9ralistes par bassin de vie en France m\u00e9tropolitaine.  Cette page est un r\u00e9sum\u00e9 du travail effectu\u00e9. Le notebook contenant l'ensemble du code se trouve ici.</p> <p>Donn\u00e9es utilis\u00e9es</p> <ul> <li>un fichier .xlsx regroupant le nombre de m\u00e9decins g\u00e9n\u00e9ralistes par commune (source : Observatoire des territoires / ann\u00e9e 2020)</li> <li>un fichier .csv contenant la population de chaque commune au recensement de 2019 (source : INSEE)</li> <li>un fichier .geojson regroupant les bassins de vie ainsi que leurs contours g\u00e9ographiques (source : INSEE)</li> <li>un fichier .geojson des diff\u00e9rentes communes fran\u00e7aises avec leurs donn\u00e9es g\u00e9ographiques (source : https://github.com/gregoiredavid/france-geojson )</li> </ul> <p>On peut voir que les donn\u00e9es sur la population et le nombre de m\u00e9decins ne sont pas de la m\u00eame ann\u00e9e. Mais \u00e0 une ann\u00e9e pr\u00e8s, il y a peu de chances qu'il y ait eu une forte variation de ces donn\u00e9es. De m\u00eame en 2022 la population et le nombre de m\u00e9decins des communes a sans-doute un peu chang\u00e9 mais le r\u00e9sultat obtenu pour l'ann\u00e9e 2020 donne une bonne id\u00e9e de la densit\u00e9 de m\u00e9decins par bassin de vie aujourd'hui en 2022.</p> <p>Modules utilis\u00e9s</p> <p>Comme dit aupravant, j'ai utilis\u00e9 le langage Python pour r\u00e9aliser cette carte. Voici les modules que j'ai utilis\u00e9s :</p> <ul> <li>le module pandas pour lire les fichiers csv et xlsx, convertir les donn\u00e9es en dataframes et faire des jointures de ces dataframes</li> <li>le module geopandas pour lire les fichiers geojson, convertir les donn\u00e9es en GeoDataFrames ainsi que pour faire des jointures spatiales</li> <li>le module matplotlib pour la cr\u00e9ation de la carte</li> </ul>"},{"location":"projets/medecins/#nettoyage-des-donnees","title":"Nettoyage des donn\u00e9es","text":"<p>La premi\u00e8re op\u00e9ration a \u00e9t\u00e9 de nettoyer les donn\u00e9es. Je ne pr\u00e9senterai pas le code correspondant \u00e0 cette partie ici (se r\u00e9f\u00e9rer au notebook). Voici ce que j'ai pu observer et faire :</p> <ul> <li>Il n'y avait pas de donn\u00e9es manquantes dans les fichiers. Je n'ai rien eu \u00e0 faire de ce c\u00f4t\u00e9.</li> <li>Il n'y avait pas de donn\u00e9es en doublons.</li> <li>Il n'y avait pas de donn\u00e9es abb\u00e9rantes.</li> <li>En revanche, la population de chaque commune \u00e9tait au format str. J'ai donc converti cette variable au format int.</li> <li>Le nombre de communes n'\u00e9tait pas le m\u00eame dans chaque fichier. Apr\u00e8s inspection, je me suis rendu compte que certains fichiers ne contenaient que les donn\u00e9es de France m\u00e9tropolitaine alors que d'autres contenaient aussi des donn\u00e9es de communes d'outre-mer. De plus, dans le fichier sur les contours g\u00e9ographiques des communes, les communes de Paris, Lyon et Marseille \u00e9taient divis\u00e9es selon leurs arrondissements. Il a donc fallu faire en sorte qu'il n'y ait plus qu'une ligne pour chacune de ces villes. Dans le cas contraire, cela aurait pos\u00e9 probl\u00e8me lors des jointures avec les autres tables.</li> <li>J'ai enfin supprim\u00e9 des colonnes dont je n'avais pas besoin dans les dataframes.  </li> </ul>"},{"location":"projets/medecins/#jointure-des-tables","title":"Jointure des tables","text":"<p>Arriv\u00e9 \u00e0 ce stade, les donn\u00e9es utiles se trouvent dans quatre dataframes diff\u00e9rents :</p> <ul> <li>pop_com pr\u00e9sentant la population des communes</li> </ul> <p></p> <ul> <li>medecins pr\u00e9sentant le nombre de m\u00e9decins par commune</li> </ul> <p></p> <ul> <li>communes regroupant les contours g\u00e9ographiques des communes</li> </ul> <p></p> <ul> <li>bassins regroupant les contours g\u00e9ographiques des bassins de vie</li> </ul> <p></p> <p>J'ai commenc\u00e9 par faire une jointure entre pop_com et medecins. J'ai appel\u00e9 la dataframe obtenue med_pop_com.</p> <p><pre><code>med_pop_com = pop_com.merge(medecins, how='left', left_on='Code', right_on='codgeo')\nmed_pop_com.head()\n</code></pre> </p> <p>Ensuite, je n'ai gard\u00e9 que les colonnes utiles et j'ai fait une jointure avec communes. La dataframe obtenue (med_pop_geo_com) regroupe donc toutes les donn\u00e9es sur les communes (population, nombre de m\u00e9decins et contours g\u00e9ographiques).</p> <pre><code>med_pop_com = med_pop_com[['Code', 'Libell\u00e9', 'Population municipale 2019', 'nb_medg']]\nmed_pop_geo_com = med_pop_com.merge(communes, how='inner', left_on='Code', right_on='INSEE_COM')\nmed_pop_geo_com.head()\n</code></pre> <p></p> <p>Il restait alors \u00e0 faire la jointure avec les donn\u00e9es sur les bassins de vie. Le probl\u00e8me \u00e9tait que je ne disposais pas de colonnes communes dans les deux tables med_pop_geo_com et bassins. J'ai contourn\u00e9 le probl\u00e8me en faisant une jointure spatiale.</p> <p>Pour faire cette jointure spatiale, j'ai d\u00e9cid\u00e9 de calculer les coordonn\u00e9es du centre g\u00e9ographique de chaque commune. Puis j'ai fait une jointure en s\u00e9lectionnant pour chaque bassin de vie les communes dont le centre se situe dans le bassin. J'ai utilis\u00e9 le param\u00e8tre <code>contains</code> de la m\u00e9thode <code>sjoin</code> du module <code>geopandas</code>. J'ai appel\u00e9 la dataframe finale df_total.</p> <pre><code># Calcul du centroid de chaque commune / utilisation d'un crs avec coordonn\u00e9es en metres pour calcul du centroid\nmed_pop_geo_com = gpd.GeoDataFrame(med_pop_geo_com).to_crs(crs=3857)   \n\n#Cr\u00e9ation des centres de chaque commune\nmed_pop_geo_com['centre']=med_pop_geo_com.geometry.centroid\n\n#suppression de la colonne geometry\nmed_pop_geo_com = med_pop_geo_com.drop('geometry', axis=1)\n\n#Renommer la colonne centre avec le nom geometry (pour la jointure avec sjoin)\nmed_pop_geo_com.rename(columns={'centre':'geometry'}, inplace=True)\n\n#retour \u00e0 un crs en degr\u00e9s\nmed_pop_geo_com = med_pop_geo_com.to_crs(crs=4326)   \nmed_pop_geo_com.head()\n</code></pre> <p></p>"},{"location":"projets/medecins/#calcul-des-densites","title":"Calcul des densit\u00e9s","text":"<p>Pour faire le calcul de densit\u00e9 de m\u00e9decins par bassin de vie, il faut conna\u00eetre la population totale de chaque bassin ainsi que son nombre de m\u00e9decins. Puis il n'y a plus qu'\u00e0 faire le quotient de ces quantit\u00e9s et multiplier par 100 000 pour obtenir le nombre de m\u00e9decins pour 100 000 habitants.</p> <p>Enfin, il suffit de faire une nouvelle jointure entre la nouvelle dataframe obtenue et df_total.</p> <pre><code># Population et nombre de m\u00e9decins par bassin\ndf_par_bassin = df_total.groupby(by='bv2012_code').agg({'nb_medg':'sum', 'Population municipale 2019':'sum'})\n\n# Densit\u00e9 de m\u00e9decins (nb pour 100 000 hbts)\ndf_par_bassin['densite']=round(df_par_bassin['nb_medg']/df_par_bassin['Population municipale 2019']*100000,2)\n\n# S\u00e9lection des colones de df_total qui serviront par la suite\ndf_total = df_total[['bv2012_name_upper', 'bv2012_code', 'geometry']]\ndf_par_bassin.rename(columns={'Population municipale 2019':'population'}, inplace=True)\n\n# jointure finale (avec suppression des doublons dus \u00e0 la jointure)\ndf_final = df_total.merge(df_par_bassin, on='bv2012_code', how='inner')\ndf_final = df_final.drop_duplicates()\ndf_final.head()\n</code></pre> <p></p>"},{"location":"projets/medecins/#creation-de-la-carte","title":"Cr\u00e9ation de la carte","text":"<p>Avant de cr\u00e9er la carte, on peut observer les principaux param\u00e8tres statistiques de la densit\u00e9 de m\u00e9decins.</p> <pre><code>df_final['densite'].describe()\n</code></pre> <p></p> <p>Remarque</p> <p>On peut remarquer qu'il existe des bassins \u00e0 densit\u00e9 nulle. Apr\u00e8s exploration des donn\u00e9es, on trouve qu'il s'agit des bassins de l'\u00cele d'Yeu et de Arzacq-Arraziguet. Apr\u00e8s une recherche sur internet, il semble exister une maison m\u00e9dicale dans ces bassins mais qui n'a sans-doute pas \u00e9t\u00e9 comptabilis\u00e9e comme m\u00e9decin g\u00e9n\u00e9raliste dans les donn\u00e9es de l'Observatoire des territoires.</p> <p>On peut ensuite faire une carte choropl\u00e8the de ces densit\u00e9s de m\u00e9decins. Pour cela, j'ai regroup\u00e9 les bassins de vie par classe. La d\u00e9limitation des classes s'est faite par quartiles. Puis j'ai utilis\u00e9 les modules geopandas et matplotlib pour cr\u00e9er la carte.</p> <pre><code>import matplotlib.pyplot as plt\n\n# Cr\u00e9ation des classes\ndf_final['classe'] = pd.qcut(df_final['densite'], 4, ['0 - 63,7', '63,7 - 80', '80 - 98,7', '+98,7'])\n\n# Cr\u00e9ation d'une dataframe avec les coordonn\u00e9es de villes \u00e0 faire appara\u00eetre sur la carte\nliste_villes=[{'ville':'Paris', 'lat':48.85341, 'long':2.3488},\n             {'ville':'Marseille', 'lat':43.299999, 'long':5.4},\n             {'ville':'Lyon', 'lat':45.7640430, 'long':4.8356590},\n             {'ville':'Toulouse', 'lat':43.6046520, 'long':1.4442090},\n             {'ville':'Bordeaux', 'lat':44.8377890, 'long':-0.5791800},\n             {'ville':'Nantes', 'lat':47.2183710, 'long':-1.5536210},\n             {'ville':'Lille', 'lat':50.6292500, 'long':3.0572560},\n             {'ville':'Strasbourg', 'lat':48.5734053, 'long':7.7521113},\n             {'ville':'Brest', 'lat':48.3903940, 'long':-4.4860760},\n             {'ville':'Orl\u00e9ans', 'lat':47.90289, 'long': 1.9038900},\n             {'ville':'Poitiers', 'lat':46.58333, 'long': 0.33333},\n             {'ville':'Caen', 'lat':49.18585, 'long':  -0.35912},\n             {'ville':'Ajaccio', 'lat':41.92723, 'long': 8.73462}]\n\ndf_villes=pd.DataFrame(liste_villes)\n\n#Transformation de la dataframe des villes en geodataframe\ngdf_villes = gpd.GeoDataFrame(df_villes, geometry=gpd.points_from_xy(df_villes.long, df_villes.lat))\n\n#cr\u00e9ation de la figure\nfig, ax = plt.subplots(1,1, figsize=(15,15))\n\n#Suppression des axes\nax.get_xaxis().set_visible(False)\nax.get_yaxis().set_visible(False)\n\n#legende\nleg_kwds = {'title' : 'Nombre de m\u00e9decins pour 100 000 hbts', 'loc':'lower left', 'fontsize':11, 'title_fontsize':11}\n\n#cr\u00e9ation de la carte\ndf_final.plot(ax=ax, column='classe', cmap='OrRd',alpha=0.8, edgecolor='black', linewidth=0.1, legend=True, legend_kwds=leg_kwds)\n\n#titre et notes\nplt.title(\"Densit\u00e9 de m\u00e9decins g\u00e9n\u00e9ralistes par bassin de vie\", fontsize=17)\nplt.figtext(0.53, 0.06,\n            \"Donn\u00e9es sur la population fran\u00e7aise : INSEE (recensement 2019) \\n Donn\u00e9es sur les m\u00e9decins : Observatoire des territoires (ann\u00e9e 2020) \\n Donn\u00e9es g\u00e9ographiques des bassins de vie : INSEE\",\n            style='italic', ha=\"center\", fontsize=11, bbox={\"facecolor\":\"white\", \"edgecolor\":\"white\",\"alpha\":0.5, \"pad\":5})\n# Placement des points\nax.scatter(df_villes.long,df_villes.lat,c='black')\n# Placement des noms de villes\nbbox=dict(boxstyle=\"round\", alpha=0.8, color='white')\nfor _,row in df_villes.iterrows():\n   ax.text(row['long']+0.13,row['lat']+0.13,row['ville'],fontsize='large', bbox=bbox)\n\n#Affichage\nplt.show()\n</code></pre>"},{"location":"projets/python_accidents/","title":"\u00c9tude des accidents corporels de la circulation routi\u00e8re entre 2005 et 2021 - Partie 1 : \u00c9tude temporelle","text":""},{"location":"projets/python_accidents/#competences-mises-en-uvre","title":"Comp\u00e9tences mises en \u0153uvre","text":"<ul> <li>Nettoyage de donn\u00e9es</li> <li>Manipulation de donn\u00e9es</li> <li>Jointures de tables</li> <li>Visualisation de donn\u00e9es</li> <li>Tests statistiques</li> </ul>"},{"location":"projets/python_accidents/#problematique","title":"Probl\u00e9matique","text":"<p>Ce projet a \u00e9t\u00e9 r\u00e9alis\u00e9 dans le cadre de ma formation au D.U. Data Analyst \u00e0 l'universit\u00e9 de Cergy. Mon but \u00e9tait de mener une \u00e9tude temporelle des accidents corporels de la circulation routi\u00e8re et d'analyser l'influence des conditions m\u00e9t\u00e9orologiques et de limunosit\u00e9 sur la gravit\u00e9 des accidents. Cette partie pr\u00e9sente l'\u00e9tude temporelle.</p> <p>Le jeu de donn\u00e9es est fourni par l' Observatoire National Interminist\u00e9riel de la S\u00e9curit\u00e9 Routi\u00e8re (ONISR) sur le site https://www.data.gouv.fr/. Il contient les informations sur les accidents corporels de la circulation routi\u00e8re, c'est \u00e0 dire sur les accidents ayant caus\u00e9 au moins un bless\u00e9 (par commodit\u00e9, on utilisera simplement le terme \u00ab accidents \u00bb dans la suite). Il est constitu\u00e9 de quatre fichiers csv par ann\u00e9e :</p> <ul> <li>le fichier caracteristiques contient les donn\u00e9es des caract\u00e9ristiques de l'accident (date, heure, conditions m\u00e9t\u00e9o,...)</li> <li>le fichier lieux contient les donn\u00e9es sur le type de route, l'\u00e9tat de la surface (normale, mouill\u00e9e,...),...</li> <li>le fichier vehicules contient les informations sur les v\u00e9hicules impliqu\u00e9s dans l'accident</li> <li>le fichier usagers contient les informations sur les personnes impliqu\u00e9es dans l'accident</li> </ul> <p>L'ensemble du projet est cod\u00e9 en python et contient trois notebooks accessible sur mon compte github</p>"},{"location":"projets/python_accidents/#concatenation-nettoyage-et-chargement-des-donnees","title":"Concat\u00e9nation, nettoyage et chargement des donn\u00e9es","text":"<p>La premi\u00e8re op\u00e9ration a \u00e9t\u00e9 de concat\u00e9ner les donn\u00e9es de chaque ann\u00e9e pour obtenir un jeu correspondant \u00e0 l'ensemble de la p\u00e9riode 2005-2021. A l'issue de cette \u00e9tape, j'ai obtenu quatre fichiers (caracteristiques, usagers, lieux et vehicules). Je ne pr\u00e9senterai pas ici les \u00e9tapes de ce travail. Pour plus de d\u00e9tails, se r\u00e9f\u00e9rer au notebook.</p> <p>La deuxi\u00e8me \u00e9tape a \u00e9t\u00e9 de nettoyer les donn\u00e9es des quatre fichiers. Un gros travail de v\u00e9rification et de recodage des donn\u00e9es a \u00e9t\u00e9 n\u00e9cessaire. Pour plus de d\u00e9tails, se r\u00e9f\u00e9rer au notebook.</p> <p>L'ensemble de l'\u00e9tude dont les r\u00e9sultats sont pr\u00e9sent\u00e9s ci-dessous est disponible dans ce troisi\u00e8me notebook. Le code \u00e9tant long, je ne pr\u00e9senterai ici que les r\u00e9sultats obtenus.</p>"},{"location":"projets/python_accidents/#evolution-du-nombre-daccidents-de-morts-et-de-blesses-hospitalises","title":"\u00c9volution du nombre d'accidents, de morts et de bless\u00e9s hospitalis\u00e9s","text":""},{"location":"projets/python_accidents/#quantification-et-representation-de-cette-evolution","title":"Quantification et repr\u00e9sentation de cette \u00e9volution","text":"<p>Sur l'ensemble des 17 ann\u00e9es, on d\u00e9nombre 1 121 571 accidents soit une moyenne de 65 975 accidents par an. Mais comment a \u00e9volu\u00e9 le nombre d'accidents au cours de la p\u00e9riode 2005-2021 ? </p> <p></p> <p>On constate une baisse du nombre d'accidents entre 2005 et 2013. Le nombre d'accidents est pass\u00e9 87 000 \u00e0 un peu plus de 58 000 sur cette p\u00e9riode. Depuis, on observe une stabilisation entre 55 000 et 60 000 accidents. La chute brutale observ\u00e9e en 2020 (47 744 accidents seulement) est bien-s\u00fbr due aux confinements d\u00e9clench\u00e9s suite \u00e0 l'\u00e9pid\u00e9mie de Covid-19. </p> <p>Qu'en est-il du nombre de morts ?</p> <p></p> <p>Le nombre de morts a suivi \u00e0 peu pr\u00e8s la m\u00eame \u00e9volution que le nombre d'accidents. Il est pass\u00e9 de 5 500 en 2005 \u00e0 3 400 en 2013. Depuis, il est relativement stable. L\u00e0-aussi, on remarque un nombre tr\u00e8s inf\u00e9rieur en 2020 avec seulement 2780 morts. </p> <p>Regardons maintenant le nombre de bless\u00e9s hospitalis\u00e9s.</p> <p></p> <p>L'\u00e9volution est la m\u00eame que pr\u00e9c\u00e9demment jusqu'en 2017. Mais on constate une forte baisse \u00e0 partir de 2018. Il faut \u00eatre prudent dans l'interpr\u00e9tation de ce constat. En effet, l'ONISR pr\u00e9cise que le processus de recensement des bless\u00e9s a chang\u00e9 en 2018 et qu'il n'est pas possible de comparer le nombre de bless\u00e9s avant et apr\u00e8s 2018.</p>"},{"location":"projets/python_accidents/#correlation-entre-le-nombre-annuel-daccidents-et-de-morts","title":"Corr\u00e9lation entre le nombre annuel d'accidents et de morts","text":"<p>Le diagramme pr\u00e9sentant ci-dessus le nombre annuel de morts en fonction du nombre annuel d'accidents sugg\u00e8re une tr\u00e8s forte corr\u00e9lation entre les deux. Le test de corr\u00e9lation de Spearman confirme une corr\u00e9lation tr\u00e8s significative au risque de 5 % (p &lt; 0.0001***) et tr\u00e8s forte (r = 0.97).</p>"},{"location":"projets/python_accidents/#correlation-entre-le-nombre-annuel-daccidents-et-de-blesses-hospitalises","title":"Corr\u00e9lation entre le nombre annuel d'accidents et de bless\u00e9s hospitalis\u00e9s","text":"<p>De la m\u00eame mani\u00e8re, le graphique pr\u00e9sentant le nombre de bl\u00e9ss\u00e9s hospitalis\u00e9s en fonction du nombre d'accidents sugg\u00e8re une corr\u00e9lation positive entre les deux variables. Le test de corr\u00e9lation de Spearman confirme cette hypoth\u00e8se au risque de 5 % : la corr\u00e9lation est tr\u00e8s significative (p &lt; 0.0001***) et tr\u00e8s forte (r = 0.95).</p>"},{"location":"projets/python_accidents/#les-mois-les-plus-accidentogenes","title":"Les mois les plus accidentog\u00e8nes","text":"<p>Dans cette partie, l'ann\u00e9e 2020 est exclue. En effet, les confinements du printemps et de la fin de l'ann\u00e9e ont eu un effet qui fausserait les chiffres et leur interpr\u00e9tation.</p> <p>Sur l'ensemble des autres ann\u00e9es, on observe un nombre mensuel moyen d'accidents de 5 593. Mais cette moyenne cache des disparit\u00e9s. En effet, le nombre mensuel d'accidents a vari\u00e9 entre 3 350 et 8 469 et on observe un \u00e9cart-type \u00e9gal \u00e0 1053. </p> <p>On peut se demander s'il existe des mois plus accidentog\u00e8nes que d'autres. Le diagramme ci-dessous montre que le nombre mensuel moyen d'accidents est plus \u00e9lev\u00e9 en octobre, juin et septembre avec respectivement 6 374, 6 325 et 6 173 accidents en moyenne. Les diagrammes en bo\u00eetes montrent \u00e9galement que les m\u00e9dianes de ces trois mois sont plus \u00e9lev\u00e9es que les autres (m\u00e9dianes respectives de 5 940, 5 870 et 5 778). A l'oppos\u00e9, le mois de f\u00e9vrier ne compte qu'une moyenne de 4 485 accidents et une m\u00e9diane de 4 255. </p> <p>Le test de Kruskal-Wallis permet d'affirmer que la diff\u00e9rence des m\u00e9dianes est significative (\ud835\udf12\u00b2(11) = 56.59, \ud835\udc5d &lt; 0.001***).</p> <p> </p>"},{"location":"projets/python_accidents/#taux-de-mortalite-par-mois-de-lannee","title":"Taux de mortalit\u00e9 par mois de l'ann\u00e9e","text":"<p>Dans cette partie, nous utiliserons le taux de mortalit\u00e9 d\u00e9fini comme \u00e9tant le nombre de morts pour 100 accidents. On peut remarquer que les mois de juillet, ao\u00fbt et d\u00e9cembre sont ceux qui ont les taux de mortalit\u00e9 moyens les plus importants. Les autres mois ont des taux de mortalit\u00e9 moyens plus proches les uns des autres. </p> <p> </p> <p>Une ANOVA permet de conclure \u00e0 une diff\u00e9rence tr\u00e8s significative des taux de mortalit\u00e9 (F(11, 180)=23.18, p&lt;0.000***). Le test de comparaisons multiples de Tuckey r\u00e9v\u00e8le une diff\u00e9rence significative du taux de mortalit\u00e9 moyen du mois d'ao\u00fbt avec tous les autres mois (\u00e0 l'exception de juillet). Quand \u00e0 celui du mois de juillet, il est significativement diff\u00e9rent de celui des autres mois \u00e0 l'exception des mois de d\u00e9cembre et ao\u00fbt. Enfin, si on excepte les mois de juillet et ao\u00fbt, le taux de mortalit\u00e9 moyen du mois de d\u00e9cembre est significativement diff\u00e9rent de celui des autres mois mise \u00e0 part f\u00e9vrier.</p>"},{"location":"projets/python_accidents/#taux-de-mortalite-par-jour-de-la-semaine","title":"Taux de mortalit\u00e9 par jour de la semaine","text":"<p>Quel que soit le mois de l'ann\u00e9e, le taux de mortalit\u00e9 est plus important le week-end qu'en semaine.</p> <p></p> <p>Si on calcule la diff\u00e9rence entre le taux de mortalit\u00e9 le week-end et la semaine, on remarque que les mois de juillet et ao\u00fbt ont une des diff\u00e9rences les plus faibles. Le grand taux de mortalit\u00e9 de ces deux mois ne s'explique donc pas par les accidents caus\u00e9s lors des week-ends de grands d\u00e9parts en vacances. Leur taux de mortalit\u00e9 reste plus \u00e9lev\u00e9 que celui des autres mois quel que soit le jour de la semaine.</p> <p></p>"},{"location":"projets/python_accidents/#nombre-moyen-daccidents-par-heure-de-la-journee","title":"Nombre moyen d'accidents par heure de la journ\u00e9e","text":"<p>L'\u00e9tude du nombre d'accidents par heure de la journ\u00e9e a \u00e9t\u00e9 effectu\u00e9e uniquement sur l'ann\u00e9e 2019. En effet, dans le jeu de donn\u00e9es le codage des heures lors des ann\u00e9es pr\u00e9c\u00e9dentes est ambig\u00fc. Pour ne pas risquer de mauvaise interpr\u00e9tation, ces ann\u00e9es n'ont pas \u00e9t\u00e9 prises en compte. De plus, les confinements et couvre-feux des ann\u00e9es 2020 et 2021 faussent les donn\u00e9es.</p> <p></p> <p>Sur le graphique ci-dessus, on remarque deux pics : un pic le matin principalement entre 8h et 9h, et un pic en fin d'apr\u00e8s-midi entre 17h et 19h. On peut penser aux horaires de trajets domicile-travail, ce qui se confirme pour le pic du matin si on regarde la proportion d'accidents par type de trajet (voir ci-dessous). Cependant, le soir ce sont les trajets pour loisir qui pr\u00e9dominent. Il faut toutefois prendre cette information avec pr\u00e9caution : un certain nombre de personnes peuvent aller faire du sport ou retrouver des amis directement apr\u00e8s avoir quitt\u00e9 le travail, sans repasser par chez eux. Ce type de trajets est peut-\u00eatre class\u00e9 dans les trajets loisirs.</p> <p></p>"},{"location":"projets/python_accidents/#taux-de-mortalite-par-heure-de-la-journee","title":"Taux de mortalit\u00e9 par heure de la journ\u00e9e","text":"<p>Si le nombre d'accidents est plus important en journ\u00e9e, le taux de mortalit\u00e9 des accidents est plus important la nuit. C'est en effet entre minuit et 7h qu'il est le plus haut avec un pic \u00e0 12,5 morts pour cent accidents corporels entre 4h et 5h.</p> <p></p>"},{"location":"projets/python_accidents/#carte-interactive-des-accidents-dans-les-cotes-darmor","title":"Carte interactive des accidents dans les C\u00f4tes d'Armor","text":"<p>La carte ci-dessous pr\u00e9sente les accidents dans les C\u00f4tes d'Armor sur la p\u00e9riode 2019-2021. Ce sont les seules ann\u00e9es pour lesquelles le jeu de donn\u00e9es donne la latitude et la longitude de chaque accident.</p>"},{"location":"projets/python_accidents2/","title":"\u00c9tude des accidents corporels de la circulation routi\u00e8re entre 2005 et 2021 - Partie 2 : Influence des conditions m\u00e9t\u00e9orologiques et de luminosit\u00e9 sur la gravit\u00e9 des accidents","text":""},{"location":"projets/python_accidents2/#la-gravite-des-accidents-depend-elle-de-la-luminosite","title":"La gravit\u00e9 des accidents d\u00e9pend-elle de la luminosit\u00e9 ?","text":"<p>Cette partie de l'\u00e9tude porte sur l'ensemble de la p\u00e9riode 2005-2021 hors ann\u00e9e 2020. En effet, les confinements pourraient biaiser les r\u00e9sultats. En comptabilisant le nombre de bless\u00e9s, tu\u00e9s et personnes indemnes lors des accidents en fonction des conditions de luminosit\u00e9, nous obtenons le tableau de contingence suivant :</p> Indemnes Tu\u00e9s Hospitalis\u00e9s Bless\u00e9s l\u00e9gers Jour 732 839 37 790 329 312 623 798 Aube/Cr\u00e9puscule 58 738 4 797 32 470 52 372 Nuit sans \u00e9clairage 68 569 16 577 64 850 61 838 Nuit avec \u00e9clairage \u00e9teint 7 855 714 4 165 7 836 Nuit avec \u00e9clairage allum\u00e9 159 579 7 171 70 363 165 063 <p>Le test du \ud835\udf12\u00b2 permet d'affirmer qu'il existe une association significative entre gravit\u00e9 et luminosit\u00e9 au risque de 5% (\ud835\udf12\u00b2(12)=48 676 ; p&lt;0.0001***). La force de l'association est faible (V de Cramer \u00e9gal \u00e0 0.07). Le mosaicplot ci-dessous montre une surrepr\u00e9sentation des morts et bless\u00e9s graves lors des accidents la nuit sans \u00e9clairage et lors de l'aube et du cr\u00e9puscule. En revanche, ils sont sous-repr\u00e9sent\u00e9s lors des accidents en plein jour pour lesquels ce sont les personnes indemnes qui sont surrepr\u00e9sent\u00e9es. La nuit dans les lieux avec \u00e9clairage public, il y a surrepr\u00e9sentation des bless\u00e9s l\u00e9gers.</p> <p></p>"},{"location":"projets/python_accidents2/#la-gravite-des-accidents-depend-elle-des-conditions-meteorologiques","title":"La gravit\u00e9 des accidents d\u00e9pend-elle des conditions m\u00e9t\u00e9orologiques ?","text":"<p>Nous pouvons faire le m\u00eame type d'\u00e9tude sur l'influence des conditions m\u00e9t\u00e9orologiques.</p> Indemnes Tu\u00e9s Hospitalis\u00e9s Bless\u00e9s l\u00e9gers Soleil 834 124 52 052 401 595 733 001 Pluie l\u00e9g\u00e8re 104 465 5 979 46 804 103 245 Pluie forte 21 792 1 725 11 812 19 865 Neige/gr\u00eale 6 516 491 3 372 5 376 Brouillard/fum\u00e9e 6 326 1 131 5 099 4 910 Vent fort/temp\u00eate 2 090 342 1 671 1 876 Temps \u00e9blouissant 12 664 1 236 8 020 7 333 Temps couvert 33 609 3 220 18 113 29 726 Autre 5 930 860 4 637 5 514 <p>L\u00e0-encore, le test du \ud835\udf12\u00b2 permet d'affirmer qu'il existe une association significative entre gravit\u00e9 et conditions m\u00e9t\u00e9o au risque de 5% (\ud835\udf12\u00b2(24)=8 136 ; p&lt;0.0001***). La force de l'associaition est faible (V de Cramer \u00e9gal \u00e0 0.02). Le mosaicplot montre une surrepr\u00e9sentation des tu\u00e9s et bless\u00e9s graves dans toutes les situations sauf les conditions normales et de pluie l\u00e9g\u00e8re. Lors de conditions normales, les personnes indemnes sont surrepr\u00e9sent\u00e9es et par temps de pluie faible, les blessers l\u00e9gers sont surrepr\u00e9sent\u00e9s.</p> <p></p>"},{"location":"projets/python_accidents2/#la-gravite-des-accidents-depend-elle-de-letat-de-la-surface-de-la-route","title":"La gravit\u00e9 des accidents d\u00e9pend-elle de l'\u00e9tat de la surface de la route ?","text":"<p>\u00c0 nouveau nous pouvons utiliser un test du \ud835\udf12\u00b2 pour d\u00e9terminer s'il y a association entre gravit\u00e9 et \u00e9tat de la surface de la route.</p> Indemnes Tu\u00e9s Hospitalis\u00e9s Bless\u00e9s l\u00e9gers Normale 816 662 51 426 392 165 705 418 Mouill\u00e9e 170 149 12 479 83 494 165 340 Flaques 1 044 127 842 1 133 Inond\u00e9e 450 73 309 409 Enneig\u00e9e 3 315 253 1 734 2 710 Boue 306 67 422 346 Verglas 4 626 671 4 249 4 822 Corps gras/huile 1 270 125 1 134 2 323 Autre 3 290 674 3 727 3 521 <p>le test du \ud835\udf12\u00b2 permet d'affirmer qu'il existe une association significative entre gravit\u00e9 et \u00e9tat de la surface de la route au risque de 5% (\ud835\udf12\u00b2(24)=5 216 ; p&lt;0.0001***). La force de l'associaition est faible (V de Cramer \u00e9gal \u00e0 0.02). Le mosaicplot montre une surrepr\u00e9sentation des tu\u00e9s et bless\u00e9s graves dans toutes les situations sauf les conditions normales et de route mouill\u00e9e. Pour cette derni\u00e8re situation, les tu\u00e9s sont surrepr\u00e9sent\u00e9s mais les bless\u00e9s graves sont sous-repr\u00e9sent\u00e9s. Lors de conditions normales, les personnes indemnes sont surrepr\u00e9sent\u00e9es.</p> <p></p>"},{"location":"projets/python_accidents2/#mortalite-des-accidents-modele-de-regression-logistique","title":"Mortalit\u00e9 des accidents : mod\u00e8le de r\u00e9gression logistique","text":"<p>Nous pouvons \u00e9tudier l'influence de chacun des facteurs pr\u00e9c\u00e9dents mais cette fois sur la mortalit\u00e9 des accidents. Pour cela, nous pouvons utiliser un mod\u00e8le de r\u00e9gression logistique pour calculer les Odds Ratios de chaque facteur par rapport \u00e0 des conditions \u00ab normales \u00bb. Le mod\u00e8le donne les r\u00e9sultats regroup\u00e9s dans le forestplot suivant :</p> <p></p> <p>On remarque que la luminosit\u00e9 est le facteur ayant le plus d'influence. Particuli\u00e8rement, par rapport \u00e0 un accident ayant lieu en plein jour, un accident a bien plus de chances d'\u00eatre mortel s'il a lieu la nuit sur une route sans \u00e9clairage (O.R. = 3.98 ; C.I. = [3.89 ; 4.06] ; p&lt;0.0001***). De mani\u00e8re g\u00e9n\u00e9rale, des conditions de faible luminosit\u00e9 sans \u00e9clairage augmente le risque qu'un accident soit mortel par rapport \u00e0 . En revanche, un accident ayant lieu la nuit dans une zone avec \u00e9clairage public a moins de chance d'\u00eatre mortel qu'un accident en plein jour (O.R. = 0.8 ; C.I. = [0.78 ; 0.82] ; p&lt;0.0001***). Il est important ici de rappeler qu'il ne s'agit pas d'un lien de cause \u00e0 effet et il serait int\u00e9ressant d'essayer de comprendre ce r\u00e9sultat. On peut notamment remarquer qu'un accident ayant lieu dans une zone avec \u00e9clairage public se situe g\u00e9n\u00e9ralement en agglom\u00e9ration alors que la cat\u00e9gorie \u00ab plein jour \u00bb regroupe les accidents de tous les types de lieux. Cela peut avoir une influence.</p> <p>Concernant les conditions m\u00e9t\u00e9orologiques, un accident ayant lieu par pluie l\u00e9g\u00e8re a moins de chances d'\u00eatre mortel qu'un accident par conditions normales (O.R. = 0.73 ; C.I. = [0.7 ; 0.76] ; p&lt;0.0001***). On ne peut pas conclure \u00e0 un effet significatif de la gr\u00eale, la neige ou d'une pluie forte. En revanche, les autres conditions augmentent le risque qu'un accident soit mortel par rapport \u00e0 des conditions normales.</p> <p>Enfin, concernant l'\u00e9tat de surface de la route, une route mouill\u00e9e/inond\u00e9e/avec flaques augmentent le risque qu'un accident soit mortel par rapport \u00e0 une route s\u00e8che. Les autres effets sont non significatifs \u00e0 l'exception du verglas mais dont l'influence est moins important que celui d'une route mouill\u00e9e. Il est important de noter que l'effet du verglas est bien plus important si on utilise un mod\u00e8le de r\u00e9gression logistique ne tenant compte que de l'\u00e9tat de la route. Comment expliquer que l'effet soit r\u00e9duit dans le mod\u00e8le tenant compte des trois variables ? En fait, l'\u00e9tat de la route est li\u00e9 aux conditions m\u00e9t\u00e9os (\ud835\udf12\u00b2(20)=2 137 610 ; p&lt;0.0001***) et aux conditions de luminosit\u00e9 (\ud835\udf12\u00b2(16)=58 882 ; p&lt;0.0001***). Dans le mod\u00e8le avec trois variables explicatives, l'effet du verglas a \u00e9t\u00e9 absorb\u00e9 par les effets des conditions m\u00e9t\u00e9os et de luminosit\u00e9.</p>"},{"location":"projets/seismes/","title":"Carte des s\u00e9ismes dans le monde en 2022","text":""},{"location":"projets/seismes/#competences-mises-en-uvre","title":"Comp\u00e9tences mises en \u0153uvre","text":"<ul> <li>Nettoyage et manipulations de donn\u00e9es</li> <li>Visualisation de donn\u00e9es</li> </ul>"},{"location":"projets/seismes/#problematique","title":"Probl\u00e9matique","text":"<p>Ce mini-projet a pour seul but de cr\u00e9er une carte repr\u00e9sentant les s\u00e9ismes de magnitude sup\u00e9rieure \u00e0 4,5 ayant eu lieu en 2022. Le choix de prendre les s\u00e9ismes de magnitude sup\u00e9rieure \u00e0 4,5 a \u00e9t\u00e9 fait pour ne consid\u00e9rer que les s\u00e9ismes les plus importants. On ignore donc ici une grande partie des tremblements de terre car beaucoup ont une magnitude inf\u00e9rieure \u00e0 4,5 voire ne sont m\u00eame pas ressentis par l'homme (magnitude inf\u00e9rieure \u00e0 3).</p> <p>Le notebook contenant le code ainsi que les fichiers de donn\u00e9es sont disponibles ici.</p>"},{"location":"projets/seismes/#importation-des-donnees-et-selection-des-variables-utiles","title":"Importation des donn\u00e9es et s\u00e9lection des variables utiles","text":"<p>Les donn\u00e9es sont issues de l'US Geological Survey (https://www.usgs.gov/programs/earthquake-hazards/earthquakes, 2023). Le site de l'USGS limite le nombre de donn\u00e9es t\u00e9l\u00e9chargeables en un seul fichier. Il a donc \u00e9t\u00e9 n\u00e9cessaire de t\u00e9l\u00e9charger deux fichiers (format geojson) pour obtenir l'ensemble des s\u00e9ismes. La premi\u00e8re \u00e9tape a donc \u00e9t\u00e9 d'importer les deux fichiers sous forme de deux dataframes avec le module geopandas, puis de les concat\u00e9ner. Avant de faire cela, je me suis bien-s\u00fbr assur\u00e9 que les deux dataframes contenaient les m\u00eames colonnes et qu'il n'y avait pas de probl\u00e8mes de donn\u00e9es manquantes dans ces colonnes.</p> <pre><code>import geopandas as gpd\nimport pandas as pd\n\n# Importation\ndf_seismes1 = gpd.read_file('seismes01-06.geojson')\ndf_seismes2 = gpd.read_file('seismes07-12.geojson')\n\n# Selection des colonnes\ndf_seismes1 = df_seismes1[['id', 'mag', 'place', 'time', 'geometry']]\ndf_seismes2 = df_seismes2[['id', 'mag', 'place', 'time', 'geometry']]\n\n# Concatenation\ndf_seismes = pd.concat([df_seismes1, df_seismes2])\n\n# Affichage des premi\u00e8res lignes\ndf_seismes.head()\n</code></pre> <p></p> <p>On se retrouve avec une seule table dans laquelle on peut v\u00e9rifier qu'il n'y a pas de doublons gr\u00e2ce \u00e0 la m\u00e9thode <code>duplicated</code> du module <code>pandas</code>. \u00c9tant donn\u00e9 que ce n'est pas le cas, passons \u00e0 la suite.</p>"},{"location":"projets/seismes/#courte-description-des-seismes","title":"Courte description des s\u00e9ismes","text":"<p>On peut obtenir un r\u00e9sum\u00e9 statistique de la magnitude des s\u00e9ismes \u00e0 l'aide de la m\u00e9thode <code>describe</code> de <code>pandas</code>.</p> <pre><code>df_seismes['mag'].describe()\n</code></pre> <p></p> <p>On s'aper\u00e7oit alors qu'en 2022 :</p> <ul> <li>Il y a eu 8114 s\u00e9ismes de magnitude sup\u00e9rieure \u00e0 4,5.</li> <li>Le s\u00e9isme le plus important a eu une magnitude de 7,6.</li> <li>50 % des s\u00e9ismes \u00e9taient de magnitudes inf\u00e9rieures ou \u00e9gales \u00e0 4,7.</li> <li>75 % des s\u00e9ismes \u00e9taient de magnitudes inf\u00e9rieures ou \u00e9gales \u00e0 4,9.</li> </ul> <p>Les s\u00e9ismes de magnitude \u00e9lev\u00e9e sont donc plut\u00f4t rares (heureusement pour nous !). On peut tracer un histogramme de ces s\u00e9ismes pour mieux se rendre compte de leur distribution suivant la magnitude.</p> <pre><code>import matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Reindexation car la dataframe poss\u00e8de des lignes avec le m\u00eame index\n# du \u00e0 la concat\u00e9nation de deux dataframes\ndf_seismes.reset_index(drop=True, inplace=True)\n\n# Cr\u00e9ation de l'histogramme\nfig, ax = plt.subplots(figsize=(8,4))\nsns.histplot(x='mag', data=df_seismes, bins=[4.5, 5, 5.5, 6, 6.5, 7, 7.5, 8])\nplt.xlabel('Magnitude')\nplt.ylabel('Nombre de s\u00e9ismes')\nplt.title('R\u00e9partition des s\u00e9ismes de magnitude sup\u00e9rieure \u00e0 4,5 en 2022')\nplt.show()\n</code></pre> <p></p> <p>On voit bien que tr\u00e8s peu de s\u00e9ismes ont une forte magnitude.</p>"},{"location":"projets/seismes/#carte-des-seismes","title":"Carte des s\u00e9ismes","text":"<p>Passons \u00e0 ce qui nous int\u00e9resse : la carte des s\u00e9ismes. Pour r\u00e9aliser cette carte, j'ai trac\u00e9 un nuage de points (scatterplot) repr\u00e9sentant chaque s\u00e9isme suivant sa longitude en abscisse et sa latitude en ordonn\u00e9e. Ce nuage de points se fait par dessus un fond de carte du monde. Il nous faut donc importer les donn\u00e9es permettant d'afficher ce fond de carte. L\u00e0-aussi, j'ai utilis\u00e9 un fichier geojson.</p> <p>Pour cr\u00e9er une carte, il faut d\u00e9finir le type de projection du globe terrestre sur un plan. Ici j'ai utilis\u00e9 la projection Mercator.</p> <pre><code># Chargement du fichier\ncarte = gpd.read_file('world_map.json')\n\n# Changement de la projection vers la projection Mercator\ncarte = carte.to_crs('EPSG:3395')\n\n#Affichage du fond de carte\ncarte.plot(figsize=(10,10))\nplt.show()\n</code></pre> <p></p> <p>Comme on peut le voir, nous avons notre fond de carte. Il ne nous reste plus qu'\u00e0 en modifier l'aspect et repr\u00e9senter les s\u00e9ismes par des disques. Mais pour cela il faut :</p> <ul> <li>convertir les donn\u00e9es g\u00e9ospatiales de df_seismes pour avoir le m\u00eame CRS (projection Mercator)</li> <li>r\u00e9cup\u00e9rer la longitude et la latitude de chaque s\u00e9isme dans la colonne geometry</li> </ul> <p>On peut ensuite cr\u00e9er la carte en utilisant des points de diff\u00e9rentes couleurs (voir le param\u00e8tre <code>c</code> de la m\u00e9thode <code>scatter</code> de <code>matplotlib</code> qui indique quelles donn\u00e9es utiliser pour la couleur des points et le param\u00e8tre <code>cmap</code> qui donne l'\u00e9chelle de couleurs \u00e0 utiliser) mais aussi de diff\u00e9rentes tailles. Pour cela, j'ai cr\u00e9\u00e9 une liste <code>s</code> des tailles en fonction de la magnitude des s\u00e9ismes.</p> <pre><code># Changement CRS\ndf_seismes=df_seismes.to_crs('EPSG:3395')\n# Cr\u00e9ation de colonnes correspondant \u00e0 la latitude et la longitude de chaque seisme\ndf_seismes['lat']=df_seismes['geometry'].y\ndf_seismes['long']=df_seismes['geometry'].x\n\n#Cr\u00e9ation d'une liste de rayons des disques repr\u00e9sentant les s\u00e9ismes en fonction de leur magnitude\ns=[(mag-3.5)**5 for mag in df_seismes['mag']]\n\n# Cr\u00e9ation de la carte\nfig,ax = plt.subplots(1,1,figsize=(25,20), facecolor='white')\ncarte_seismes = carte.plot(ax=ax, color=\"black\", edgecolor='white', linewidth=0.2)\n\n# Suppression des axes\nax.get_xaxis().set_visible(False)\nax.get_yaxis().set_visible(False)\n\n# Couleur de fond gris fonc\u00e9\nax.set_facecolor(\"#202020\")\n\n# Repr\u00e9sentation des seismes\nax.scatter(df_seismes['long'],df_seismes['lat'], marker=\"o\", s=s,\n           c=df_seismes['mag'] ,cmap='autumn_r', \n           edgecolors=None, alpha=0.5)\nplt.title(\"S\u00e9ismes dans le monde en 2022 (magnitude sup\u00e9rieure \u00e0 4,5)\", fontsize=15)\n\n#Cr\u00e9ation d'une \u00e9chelle de couleur pour la l\u00e9gende\nsm = plt.cm.ScalarMappable(cmap='autumn_r')\nsm.set_clim(vmin=4.5, vmax=7.6)\nplt.colorbar(sm, label=\"Magnitude\", fraction=0.02, shrink=0.4, orientation='horizontal',pad=0.03)\n\n# Texte indiquant la source des donn\u00e9es\nplt.figtext(0.51, 0.08,\n            \"Source : U.S. Geological Survey (https://www.usgs.gov/programs/earthquake-hazards/earthquakes)\",\n            style='italic', ha=\"center\", fontsize=11, bbox={\"facecolor\":\"white\", \"edgecolor\":\"white\", \"pad\":-10})\n\n# Exportation au format png\nimage=plt.gcf()\nimage.savefig('seismes', bbox_inches='tight', dpi=200)\n\n#Affichage\nplt.show()\n</code></pre>"},{"location":"projets/sql_football/","title":"R\u00e9sultats des championnats europ\u00e9ens de football entre 2005 et 2021","text":""},{"location":"projets/sql_football/#competences-mises-en-uvre","title":"Comp\u00e9tences mises en \u0153uvre","text":"<ul> <li>Requ\u00eates de base </li> <li>Utilisation de Common Table Expressions (CTE)</li> <li>Utilisation de Window Functions</li> </ul>"},{"location":"projets/sql_football/#base-de-donnees","title":"Base de donn\u00e9es","text":"<p>La base de donn\u00e9es utilis\u00e9e est en libre acc\u00e8s sur www.kaggle.fr. Il s'agit d'une base de donn\u00e9es SQLite contenant les r\u00e9sultats des matchs de football des championnats europ\u00e9ens entre les saisons 2005-2006 et 2020-2021. La base contient deux tables :</p> <ul> <li> <p>Table divisions :</p> <ul> <li>division : code du championnat</li> <li>name : nom du championnat</li> <li>country : pays du championnat</li> </ul> </li> <li> <p>Table matchs:</p> <ul> <li>Div : code du championnat</li> <li>Date : date du match</li> <li>HomeTeam : \u00e9quipe \u00e0 domicile</li> <li>AwayTeam : \u00e9quipe visiteuse</li> <li>FTHG : nombre de buts marqu\u00e9s par l'\u00e9quipe \u00e0 domicile</li> <li>FTAG : nombre de buts marqu\u00e9s par l'\u00e9quipe visiteuse</li> <li>FTR : R\u00e9sultat final (H=victoire de l'\u00e9quipe \u00e0 domicile, A=victoire de l'\u00e9quipe visiteuse, D=match nul)</li> <li>season : saison </li> </ul> </li> </ul>"},{"location":"projets/sql_football/#objectif","title":"Objectif","text":"<p>Il ne s'agit pas ici d'un projet. J'ai choisi d'\u00e9crire des questions et d'y r\u00e9pondre en effectuant des requ\u00eates sur la base de donn\u00e9es. L'ensemble des requ\u00eates ont \u00e9t\u00e9 r\u00e9alis\u00e9es sous le logiciel DBeaver.</p>"},{"location":"projets/sql_football/#questions","title":"Questions","text":""},{"location":"projets/sql_football/#1-quelles-equipes-participaient-au-championnat-de-l1-en-france-lors-de-la-saison-2020-2021","title":"1. Quelles \u00e9quipes participaient au championnat de L1 en France lors de la saison 2020-2021 ?","text":"<pre><code>SELECT GROUP_CONCAT(Equipe) AS Equipes\nFROM(SELECT DISTINCT HomeTeam AS Equipe\nFROM matchs\nWHERE Div = 'F1' AND season = 2021\nORDER BY HomeTeam ASC);\n</code></pre> Equipes Angers, Bordeaux, Brest, Dijon, Lens, Lille, Lorient, Lyon, Marseille, Metz, Monaco, Montpellier, Nantes, Nice, Nimes, Paris SG, Reims, Rennes, St Etienne, Strasbourg"},{"location":"projets/sql_football/#2-quel-a-ete-le-nombre-moyen-de-buts-par-match-en-l1-lors-de-la-saison-2020-2021","title":"2. Quel a \u00e9t\u00e9 le nombre moyen de buts par match en L1 lors de la saison 2020-2021 ?","text":"<pre><code>SELECT ROUND(AVG(FTHG + FTAG), 1) AS Nb_buts_moyens,\nROUND(AVG(FTHG), 1) AS Nb_buts_domicile_moyen,\nROUND(AVG(FTAG), 1) AS Nb_buts_exterieur_moyen\nFROM matchs\nWHERE Div = 'F1' AND season = 2021;\n</code></pre> Nb_buts_moyens Nb_buts_domicile_moyen Nb_buts_exterieur_moyen 2,8 1,4 1,4"},{"location":"projets/sql_football/#3-quel-a-ete-le-pourcentage-de-victoires-a-domicile-de-victoires-a-lexterieur-et-de-matchs-nuls-en-l1-lors-de-la-saison-2020-2021","title":"3. Quel a \u00e9t\u00e9 le pourcentage de victoires \u00e0 domicile, de victoires \u00e0 l'ext\u00e9rieur et de matchs nuls en L1 lors de la saison 2020-2021 ?","text":"<pre><code>/*Nombre total de matchs*/\nWITH nb_matchs AS (\nSELECT COUNT(*) AS total\nFROM matchs m\nWHERE m.Div = 'F1' AND m.season = 2021\n),\n\n/*Nombre de victoires \u00e0 domicile*/\nnb_vict_dom AS (\nSELECT COUNT(*) AS total\nFROM matchs m\nWHERE m.Div = 'F1' AND m.season = 2021 AND m.FTR = 'H'\n),\n\n/*Nombre de victoires \u00e0 l'ext\u00e9rieur*/\nnb_vict_ext AS (\nSELECT COUNT(*) AS total\nFROM matchs m\nWHERE m.Div = 'F1' AND m.season = 2021 AND m.FTR = 'A'\n),\n\n/*Nombre de matchs nuls*/\nnb_nuls AS (\nSELECT COUNT(*) AS total\nFROM matchs m\nWHERE m.Div = 'F1' AND m.season = 2021 AND m.FTR = 'D'\n)\n\n/*Calcul des pourcentages*/\nSELECT ROUND(d.total*100.0/m.total,1) AS Pourc_victoire_dom,\nROUND(e.total*100.0/m.total,1) AS Pourc_victoire_ext,\nROUND(n.total*100.0/m.total,1) AS Pourc_matchs_nuls\nFROM nb_matchs AS m, nb_vict_dom AS d,\nnb_vict_ext AS e,\nnb_nuls AS n;\n</code></pre> Pourc_victoire_dom Pourc_victoire_ext Pourc_matchs_nuls 37,4 37,6 25"},{"location":"projets/sql_football/#4-quel-a-ete-le-nombre-de-buts-marques-par-equipe-en-l1-en-2020-2021","title":"4. Quel a \u00e9t\u00e9 le nombre de buts marqu\u00e9s par \u00e9quipe en L1 en 2020-2021 ?","text":"<pre><code>/*Nombre de buts des \u00e9quipes \u00e0 domicile*/\nWITH buts_pour_dom AS (\nSELECT m.HomeTeam as Equipe, SUM(m.FTHG) AS Nb_buts_dom\nFROM matchs m\nWHERE m.Div = 'F1' AND m.season = 2021\nGROUP BY m.HomeTeam\n),\n\n/*Nombre de buts des \u00e9quipes \u00e0 l'ext\u00e9rieur*/\nbuts_pour_ext AS (\nSELECT m.AwayTeam as Equipe, SUM(m.FTAG) AS Nb_buts_ext\nFROM matchs m\nWHERE m.Div = 'F1' AND m.season = 2021\nGROUP BY m.AwayTeam\n)\n\n/*Nombre total de buts par \u00e9quipe*/\nSELECT Equipe, (d.Nb_buts_dom + e.Nb_buts_ext) AS Nb_buts_marqu\u00e9s\nFROM buts_pour_dom d\nINNER JOIN buts_pour_ext e\nUSING(Equipe)\nORDER BY Nb_buts_marqu\u00e9s DESC;\n</code></pre> Equipe Nb_buts_marqu\u00e9s Paris SG 86 Lyon 81 Monaco 76 Lille 64 Montpellier 60 Lens 55 Marseille 54 Rennes 52 Brest 50 Lorient 50 Nice 50 Strasbourg 49 Nantes 47 Metz 44 Bordeaux 42 Reims 42 St Etienne 42 Angers 40 Nimes 40 Dijon 25"},{"location":"projets/sql_football/#5-parmi-les-cinq-grands-championnats-angleterre-espagne-allemagne-italie-france-quelles-sont-les-5-equipes-a-avoir-gagne-le-plus-de-matchs-en-2020-2021","title":"5. Parmi les cinq grands championnats (Angleterre, Espagne, Allemagne, Italie, France), quelles sont les 5 \u00e9quipes \u00e0 avoir gagn\u00e9 le plus de matchs en 2020-2021 ?","text":"<pre><code>/*S\u00e9lection des 5 championnats*/\nWITH TopChamp AS (\nSELECT *\nFROM matchs m\nINNER JOIN divisions d\nON m.Div = d.division\nWHERE season = 2021 AND d.division IN ('E0', 'SP1', 'D1', 'I1', 'F1')\n),\n\n/*Calcul du nombre de victoires \u00e0 domicile par \u00e9quipe*/\nVictoiresDom AS (\nSELECT name AS Championnat, country AS Pays, HomeTeam AS Equipe, COUNT(*) AS Nb_Victoires\nFROM TopChamp\nWHERE FTHG&gt;FTAG\nGROUP BY name, HomeTeam\n),\n\n/*Calcul du nombre de victoires \u00e0 l'ext\u00e9rieur par \u00e9quipe*/\nVictoiresExt AS (\nSELECT name AS Championnat, country AS Pays, AwayTeam AS Equipe, COUNT(*) AS Nb_Victoires\nFROM TopChamp\nWHERE FTHG&lt;FTAG\nGROUP BY name, AwayTeam\n)\n\n/*S\u00e9lection des 5 \u00e9quipes ayant le plus de victoires*/\nSELECT d.Equipe, d.Championnat, d.Pays, (d.Nb_Victoires + e.Nb_Victoires) AS Nb_Victoires\nFROM VictoiresDOM d\nINNER JOIN VictoiresExt e\nON d.Championnat = e.Championnat AND d.Equipe = e.Equipe\nORDER BY Nb_Victoires DESC\nLIMIT 5;\n</code></pre> Equipe Championnat Pays Nb_Victoires Inter Seria A Italy 28 Man City Premier League England 27 Ath Madrid LaLiga Spain 26 Paris SG Ligue 1 France 26 Real Madrid LaLiga Spain 25"},{"location":"projets/sql_football/#6-parmi-les-cinq-grands-championnats-quelles-sont-les-5-equipes-a-avoir-marque-le-plus-de-points-en-2020-2021","title":"6. Parmi les cinq grands championnats, quelles sont les 5 \u00e9quipes \u00e0 avoir marqu\u00e9 le plus de points en 2020-2021 ?","text":"<pre><code>/*S\u00e9lection des 5 championnats*/\nWITH TopChamp AS (\nSELECT *\nFROM matchs m\nINNER JOIN divisions d\nON m.Div = d.division\nWHERE season = 2021 AND d.division IN ('E0', 'SP1', 'D1', 'I1', 'F1')\n),\n\n/*Calcul du nombre de points par \u00e9quipe par match*/\nAvecPoints AS (\nSELECT *,\nCASE\nWHEN FTHG&gt;FTAG THEN 3\nWHEN FTHG&lt;FTAG THEN 0\nELSE 1\nEND AS HomePoints,\nCASE\nWHEN FTHG&gt;FTAG THEN 0\nWHEN FTHG&lt;FTAG THEN 3\nELSE 1\nEND AS AwayPoints\nFROM TopChamp\n),\n\n/*Nombre total de points gagn\u00e9s \u00e0 domicile par \u00e9quipe*/\nPointsDom AS(\nSELECT HomeTeam AS Equipe, name AS Championnat, country AS Pays, SUM(HomePoints) AS Points\nFROM AvecPoints\nGROUP BY Championnat, Equipe\n),\n\n/*Nombre total de points gagn\u00e9s \u00e0 l'ext\u00e9rieur par \u00e9quipe*/\nPointsExt AS(\nSELECT AwayTeam AS Equipe, name AS Championnat, country AS Pays, SUM(AwayPoints) AS Points\nFROM AvecPoints\nGROUP BY Championnat, Equipe\n)\n\n/*Podium par championnat*/\nSELECT d.Equipe, d.Championnat, d.Pays, (d.Points+e.Points) AS Points\nFROM PointsExt e\nINNER JOIN PointsDom d\nON e.Championnat=d.Championnat AND e.Equipe=d.Equipe\nORDER BY Points DESC\nLIMIT 5;\n</code></pre> Equipe Championnat Pays Points Inter Seria A Italy 91 Ath Madrid LaLiga Spain 86 Man City Premier League England 86 Real Madrid LaLiga Spain 84 Lille Ligue 1 France 83"},{"location":"projets/sql_football/#7-quel-a-ete-le-podium-des-5-grands-championnats-en-2020-2021","title":"7. Quel a \u00e9t\u00e9 le podium des 5 grands championnats en 2020-2021 ?","text":"<pre><code>/*S\u00e9lection des 5 championnats*/\nWITH TopChamp AS (\nSELECT *\nFROM matchs m\nINNER JOIN divisions d\nON m.Div = d.division\nWHERE season = 2021 AND d.division IN ('E0', 'SP1', 'D1', 'I1', 'F1')\n),\n\n/*Calcul du nombre de points par \u00e9quipe par match*/\nAvecPoints AS (\nSELECT *,\nCASE\nWHEN FTHG&gt;FTAG THEN 3\nWHEN FTHG&lt;FTAG THEN 0\nELSE 1\nEND AS HomePoints,\nCASE\nWHEN FTHG&gt;FTAG THEN 0\nWHEN FTHG&lt;FTAG THEN 3\nELSE 1\nEND AS AwayPoints\nFROM TopChamp\n),\n\n/*Nombre total de points gagn\u00e9s \u00e0 domicile par \u00e9quipe*/\nPointsDom AS(\nSELECT HomeTeam AS Equipe, name AS Championnat, country AS Pays, SUM(HomePoints) AS Points\nFROM AvecPoints\nGROUP BY Championnat, Equipe\n),\n\n/*Nombre total de points gagn\u00e9s \u00e0 l'ext\u00e9rieur par \u00e9quipe*/\nPointsExt AS(\nSELECT AwayTeam AS Equipe, name AS Championnat, country AS Pays, SUM(AwayPoints) AS Points\nFROM AvecPoints\nGROUP BY Championnat, Equipe\n),\n\n/*Classement par championnat*/\nClassementChamp AS (\nSELECT d.Equipe, d.Championnat, d.Pays, (d.Points+e.Points) AS Points,\nRANK() OVER(PARTITION BY d.Championnat\nORDER BY d.Points+e.Points DESC\n) AS Classement\nFROM PointsExt e\nINNER JOIN PointsDom d\nON e.Championnat=d.Championnat AND e.Equipe=d.Equipe\n)\n\n/*Podium par championnat*/\nSELECT Championnat, Pays, Classement, Equipe, Points\nFROM ClassementChamp\nWHERE Classement&lt;4;\n</code></pre> Championnat Pays Classement Equipe Points Bundesliga Deutschland 1 Bayern Munich 78 Bundesliga Deutschland 2 RB Leipzig 65 Bundesliga Deutschland 3 Dortmund 64 LaLiga Spain 1 Ath Madrid 86 LaLiga Spain 2 Real Madrid 84 LaLiga Spain 3 Barcelona 79 Ligue 1 France 1 Lille 83 Ligue 1 France 2 Paris SG 82 Ligue 1 France 3 Monaco 78 Premier League England 1 Man City 86 Premier League England 2 Man United 74 Premier League England 3 Liverpool 69 Seria A Italy 1 Inter 91 Seria A Italy 2 Milan 79 Seria A Italy 3 Atalanta 78 Seria A Italy 3 Juventus 78"},{"location":"projets/sql_football/#8-quelles-equipes-ont-ete-en-l1-toutes-les-saisons-de-2005-a-2021","title":"8. Quelles \u00e9quipes ont \u00e9t\u00e9 en L1 toutes les saisons de 2005 \u00e0 2021 ?","text":"<pre><code>/*S\u00e9lection des \u00e9quipes qui ont toujours \u00e9t\u00e9 en Ligue 1 depuis la saison 2005-2006 */\nSELECT GROUP_CONCAT(Equipe) AS Equipes\nFROM(SELECT m.HomeTeam AS Equipe\nFROM matchs m\nWHERE m.Div = 'F1'\nGROUP BY m.HomeTeam\nHAVING COUNT(DISTINCT(season)) = (SELECT COUNT(DISTINCT season)\nFROM matchs)\n);\n</code></pre> Equipes Bordeaux, Lille, Lyon, Marseille, Nice, Paris SG, Rennes, St Etienne"},{"location":"projets/sql_football/#9-lors-de-quels-matchs-y-a-t-il-eu-le-plus-de-buts","title":"9. Lors de quel(s) match(s) y-a-t-il eu le plus de buts ?","text":"<pre><code>/*Calcul du nombre de buts par match*/\nWITH Buts_par_match AS (\nSELECT m.date AS Date, m.HomeTeam AS Equipe_domicile ,m.AwayTeam AS Equipe_ext\u00e9rieur,\nm.FTHG AS Buts_\u00e9quipe_dom, m.FTAG AS Buts_\u00e9quipe_ext, m.FTHG+m.FTAG AS Nb_total_buts\nFROM matchs m\n)\n\n/*S\u00e9lection du(des) match(s) avec le plus de buts*/\nSELECT Date, Equipe_domicile, Equipe_ext\u00e9rieur, Buts_\u00e9quipe_dom, Buts_\u00e9quipe_ext, Nb_total_buts\nFROM Buts_par_match\nWHERE Nb_total_buts = (SELECT MAX(Nb_total_buts)\nFROM Buts_par_match);\n</code></pre> Date Equipe_domicile Equipe_ext\u00e9rieur Buts_\u00e9quipe_dom Buts_\u00e9quipe_ext Nb_total_buts 2020-10-24 VVV Venlo Ajax 0 13 13"},{"location":"projets/sql_football/#10-dans-les-5-grand-championnats-lors-de-quels-matchs-y-a-t-il-eu-le-plus-de-buts-lors-de-chaque-saison","title":"10. Dans les 5 grand championnats, lors de quels matchs y-a-t-il eu le plus de buts lors de chaque saison ?","text":"<pre><code>/*Calcul du nombre de buts par match dans les 5 grands championnats*/\nWITH Buts_par_match AS (\nSELECT m.date AS Date, m.season, d.name AS Championnat, m.HomeTeam AS Equipe_domicile ,m.AwayTeam AS Equipe_ext\u00e9rieur,\nm.FTHG AS Buts_\u00e9quipe_dom, m.FTAG AS Buts_\u00e9quipe_ext, m.FTHG+m.FTAG AS Nb_total_buts\nFROM matchs m\nINNER JOIN divisions d\nON m.Div = d.division\nWHERE d.division IN ('E0', 'D1', 'I1', 'F1', 'SP1')\n),\n\n/*Calcul du nombre max de buts par saison*/\nMax_buts AS (\nSELECT season, MAX(Nb_total_buts) AS maxi\nFROM Buts_par_match\nGROUP BY season\n)\n\n/*Matchs avec le plus de buts pour chaque saison*/\nSELECT bpm.season, bpm.Date, bpm.Championnat, bpm.Equipe_domicile, bpm.Equipe_ext\u00e9rieur, bpm.Buts_\u00e9quipe_dom,\nbpm.Buts_\u00e9quipe_ext, bpm.Nb_total_buts\nFROM Buts_par_match bpm\nINNER JOIN Max_buts mb\nON bpm.season = mb.season AND bpm.Nb_total_buts = mb.maxi\nORDER BY bpm.season DESC;\n</code></pre> Season Date Championnat Equipe_domicile Equipe_ext\u00e9rieur Buts_\u00e9quipe_dom Buts_\u00e9quipe_ext Nb_total_buts 2021 2020-10-04 Premier League Aston Villa Liverpool 7 2 9 2021 2021-02-02 Premier League Man United Southampton 9 0 9 2020 2019-10-25 Premier League Southampton Leicester 0 9 9 2020 2020-03-01 Seria A Lecce Atalanta 2 7 9 2019 2018-09-02 LaLiga Barcelona Huesca 8 2 10 2018 2017-10-14 Premier League Man City Stoke 7 2 9 2018 2018-05-13 Premier League Tottenham Leicester 5 4 9 2018 2018-02-02 Ligue 1 Marseille Metz 6 3 9 2018 2017-10-15 LaLiga Betis Valencia 3 6 9 2018 2018-03-18 LaLiga Real Madrid Girona 6 3 9 2018 2018-05-13 LaLiga Levante Barcelona 5 4 9 2017 2017-05-07 Seria A Lazio Sampdoria 7 3 10 2017 2016-08-20 LaLiga Sevilla Espanol 6 4 10 2016 2015-12-20 LaLiga Real Madrid Vallecano 10 2 12 2015 2014-09-20 LaLiga La Coruna Real Madrid 2 8 10 2015 2015-04-05 LaLiga Real Madrid Granada 9 1 10 2015 2015-05-23 LaLiga Real Madrid Getafe 7 3 10 2014 2013-10-30 LaLiga Real Madrid Sevilla 7 3 10 2013 2013-03-30 Bundesliga Bayern Munich Hamburg 9 2 11 2012 2011-08-28 Premier League Man United Arsenal 8 2 10 2011 2010-08-29 Bundesliga Leverkusen M'gladbach 3 6 9 2011 2011-05-07 Bundesliga St Pauli Bayern Munich 1 8 9 2011 2010-12-04 Ligue 1 Lille Lorient 6 3 9 2011 2011-04-23 LaLiga Valencia Real Madrid 3 6 9 2011 2011-05-21 LaLiga Real Madrid Almeria 8 1 9 2010 2009-11-22 Premier League Tottenham Wigan 9 1 10 2010 2009-11-08 Ligue 1 Lyon Marseille 5 5 10 2009 2008-09-27 Bundesliga Werder Bremen Hoffenheim 5 4 9 2008 2007-09-29 Premier League Portsmouth Reading 7 4 11 2007 2007-04-01 LaLiga Santander Ath Bilbao 5 4 9 2006 2006-02-11 Bundesliga Schalke 04 Leverkusen 7 4 11"}]}